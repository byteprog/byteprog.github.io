{"meta":{"title":"乱涂乱画的小站","subtitle":"","description":"shion在 Internet 上的个人博客","author":"shion","url":"http://www.postman.life","root":"/"},"pages":[{"title":"","date":"2021-06-14T13:55:19.737Z","updated":"2021-06-14T13:55:19.737Z","comments":true,"path":"404/index.html","permalink":"http://www.postman.life/404/index.html","excerpt":"","text":""},{"title":"contributors","date":"2021-06-14T13:23:58.000Z","updated":"2021-06-14T13:23:58.659Z","comments":true,"path":"contributors/index.html","permalink":"http://www.postman.life/contributors/index.html","excerpt":"","text":""},{"title":"about me","date":"2021-06-13T16:10:42.000Z","updated":"2021-06-14T13:52:50.057Z","comments":true,"path":"about/index.html","permalink":"http://www.postman.life/about/index.html","excerpt":"","text":"💡 Introduction Name @shion Profession Java &amp; Microservice Developer Experience Since 2018 Live Shang Hai Email &#x6b;&#x77;&#x6f;&#108;&#97;&#x6e;&#x67;&#x40;&#x67;&#x6d;&#x61;&#105;&#x6c;&#46;&#x63;&#x6f;&#109; 💡 Interests Algorithms OS Street Photography"},{"title":"categories","date":"2021-06-14T13:23:15.000Z","updated":"2021-06-14T13:49:19.248Z","comments":true,"path":"categories/index.html","permalink":"http://www.postman.life/categories/index.html","excerpt":"","text":""},{"title":"faqs","date":"2021-06-14T13:21:28.000Z","updated":"2021-06-14T13:21:28.310Z","comments":true,"path":"faqs/index.html","permalink":"http://www.postman.life/faqs/index.html","excerpt":"","text":""},{"title":"tag","date":"2021-06-14T13:52:33.709Z","updated":"2021-06-14T13:52:33.709Z","comments":true,"path":"tags/index.html","permalink":"http://www.postman.life/tags/index.html","excerpt":"","text":""},{"title":"friends","date":"2021-06-14T13:53:39.000Z","updated":"2021-06-14T13:53:53.052Z","comments":true,"path":"friends/index.html","permalink":"http://www.postman.life/friends/index.html","excerpt":"","text":""},{"title":"examples","date":"2021-06-14T13:23:33.000Z","updated":"2021-06-14T13:23:33.830Z","comments":true,"path":"examples/index.html","permalink":"http://www.postman.life/examples/index.html","excerpt":"","text":""}],"posts":[{"title":"ElasticSearch常用指令","slug":"ElasticSearch常用指令","date":"2021-06-14T14:08:23.000Z","updated":"2021-06-14T14:10:28.721Z","comments":true,"path":"2021/06/14/ElasticSearch常用指令/","link":"","permalink":"http://www.postman.life/2021/06/14/ElasticSearch%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4/","excerpt":"","text":"ElasticSearch用作全文检索，一直没有好好研究它的命令，每次使用的时候都要谷歌搜索，效率太低。 本文把一些特别常用的运维及操作命令整理一下，方便归类记忆 简单查询创建Index、Type 12345678PUT /megacorp/employee/1&#123; &quot;first_name&quot; : &quot;John&quot;, &quot;last_name&quot; : &quot;Smith&quot;, &quot;age&quot; : 25, &quot;about&quot; : &quot;I love to go rock climbing&quot;, &quot;interests&quot;: [ &quot;sports&quot;, &quot;music&quot; ]&#125; 检索文档 12GET /megacorp/employee/1 //指定GET /megacorp/employee/_search //返回所有 结果 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&#123; &quot;took&quot;: 6, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; ... &#125;, &quot;hits&quot;: &#123; &quot;total&quot;: 3, &quot;max_score&quot;: 1, &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;megacorp&quot;, &quot;_type&quot;: &quot;employee&quot;, &quot;_id&quot;: &quot;3&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;first_name&quot;: &quot;Douglas&quot;, &quot;last_name&quot;: &quot;Fir&quot;, &quot;age&quot;: 35, &quot;about&quot;: &quot;I like to build cabinets&quot;, &quot;interests&quot;: [ &quot;forestry&quot; ] &#125; &#125;, &#123; &quot;_index&quot;: &quot;megacorp&quot;, &quot;_type&quot;: &quot;employee&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;first_name&quot;: &quot;John&quot;, &quot;last_name&quot;: &quot;Smith&quot;, &quot;age&quot;: 25, &quot;about&quot;: &quot;I love to go rock climbing&quot;, &quot;interests&quot;: [ &quot;sports&quot;, &quot;music&quot; ] &#125; &#125;, &#123; &quot;_index&quot;: &quot;megacorp&quot;, &quot;_type&quot;: &quot;employee&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;first_name&quot;: &quot;Jane&quot;, &quot;last_name&quot;: &quot;Smith&quot;, &quot;age&quot;: 32, &quot;about&quot;: &quot;I like to collect rock albums&quot;, &quot;interests&quot;: [ &quot;music&quot; ] &#125; &#125; ] &#125;&#125; 注意：返回结果不仅告知匹配了哪些文档，还包含了整个文档本身：显示搜索结果给最终用户所需的全部信息。 删除Index 1DELETE &#x2F;ecommerce 查询字符串 （query-string） 搜索，因为我们通过一个URL参数来传递查询信息给搜索接口 1GET &#x2F;megacorp&#x2F;employee&#x2F;_search?q&#x3D;last_name:Smith 我们仍然在请求路径中使用 _search 端点，并将查询本身赋值给参数 q= 。返回结果给出了所有的 Smith： 1234567891011121314151617181920212223242526272829&#123; ... &quot;hits&quot;: &#123; &quot;total&quot;: 2, &quot;max_score&quot;: 0.30685282, &quot;hits&quot;: [ &#123; ... &quot;_source&quot;: &#123; &quot;first_name&quot;: &quot;John&quot;, &quot;last_name&quot;: &quot;Smith&quot;, &quot;age&quot;: 25, &quot;about&quot;: &quot;I love to go rock climbing&quot;, &quot;interests&quot;: [ &quot;sports&quot;, &quot;music&quot; ] &#125; &#125;, &#123; ... &quot;_source&quot;: &#123; &quot;first_name&quot;: &quot;Jane&quot;, &quot;last_name&quot;: &quot;Smith&quot;, &quot;age&quot;: 32, &quot;about&quot;: &quot;I like to collect rock albums&quot;, &quot;interests&quot;: [ &quot;music&quot; ] &#125; &#125; ] &#125;&#125; Query 领域特定语言 （DSL） 使用 JSON 构造了一个请求。我们可以像这样重写之前的查询所有名为 Smith 的搜索 ： 12345678GET /megacorp/employee/_search&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;last_name&quot;: &quot;Fir&quot; &#125; &#125;&#125; 返回结果与之前的查询一样，但还是可以看到有一些变化。其中之一是，不再使用 query-string 参数，而是一个请求体替代。这个请求使用 JSON 构造，并使用了一个 match 查询（属于查询类型之一，后面将继续介绍）。 更复杂的搜索 1234567891011121314151617GET /megacorp/employee/_search&#123; &quot;query&quot; : &#123; &quot;bool&quot;: &#123; &quot;must&quot;: &#123; &quot;match&quot; : &#123; &quot;last_name&quot; : &quot;smith&quot; &#125; &#125;, &quot;filter&quot;: &#123; &quot;range&quot; : &#123; &quot;age&quot; : &#123; &quot;gt&quot; : 30 &#125; &#125; &#125; &#125; &#125;&#125; 这部分与我们之前使用的 match 查询 一样。这部分是一个 range 过滤器 ， 它能找到年龄大于 30 的文档，其中 gt 表示大于(great than)。 全文查询match querymatch query 用于搜索单个字段，首先会针对查询语句进行解析（经过 analyzer），主要是对查询语句进行分词，分词后查询语句的任何一个词项被匹配，文档就会被搜到，默认情况下相当于对分词后词项进行 or 匹配操作。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950语法1GET article/_search&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;title&quot;: &#123; &quot;query&quot;: &quot;Elasticsearch 查询优化&quot; &#125; &#125; &#125;&#125;语法2GET /product_center_foreground_delivery/product_center_foreground_delivery&#123; &quot;query&quot; : &#123; &quot;match&quot; : &#123; &quot;categoryType&quot; : &#123; &quot;query&quot; : &quot;13&quot; &#125; &#125; &#125;&#125;等同于 or 匹配操作，如下：GET article/_search&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;title&quot;: &#123; &quot;query&quot;: &quot;Elasticsearch 查询优化&quot;, &quot;operator&quot;: &quot;or&quot; &#125; &#125; &#125;&#125;如果想查询匹配所有关键词的文档，可以用 and 操作符连接，如下：GET article/_search&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;title&quot;: &#123; &quot;query&quot;: &quot;Elasticsearch 查询优化&quot;, &quot;operator&quot;: &quot;and&quot; &#125; &#125; &#125;&#125; 状态查询 获取所有_cat系列的操作 1234567891011121314151617181920212223242526272829curl http://localhost:9200/_cat=^.^=/_cat/allocation/_cat/shards/_cat/shards/&#123;index&#125;/_cat/master/_cat/nodes/_cat/tasks/_cat/indices/_cat/indices/&#123;index&#125;/_cat/segments/_cat/segments/&#123;index&#125;/_cat/count/_cat/count/&#123;index&#125;/_cat/recovery/_cat/recovery/&#123;index&#125;/_cat/health/_cat/pending_tasks/_cat/aliases/_cat/aliases/&#123;alias&#125;/_cat/thread_pool/_cat/thread_pool/&#123;thread_pools&#125;/_cat/plugins/_cat/fielddata/_cat/fielddata/&#123;fields&#125;/_cat/nodeattrs/_cat/repositories/_cat/snapshots/&#123;repository&#125;/_cat/templates 可以后面加一个v，让输出内容表格显示表头; pretty则让输出缩进更规范 集群状态 集群状态 1curl -X GET &quot;localhost:9200/_cluster/health?pretty&quot; 节点状态 节点简要信息 12345curl -X GET &quot;localhost:9200/_cat/nodes?pretty&amp;v&quot;ip heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name192.168.58.101 69 99 71 12.67 12.25 11.71 mdi - node-101192.168.58.103 23 99 70 14.64 13.45 12.68 mdi - node-103192.168.58.105 60 97 69 11.17 10.96 10.88 mdi * node-105 节点详细信息 1curl -X GET &quot;localhost:9200/_nodes/stats/http?pretty&quot; 后面的http是查看的属性，另外还有indices, fs, http, jvm, os, process, thread_pool, discovery等，支持组合（如indices,fs,http） 分片状态 分片 123456curl -X GET &quot;localhost:9200/_cat/shards?v&amp;pretty&quot;index shard prirep state docs store ip nodetenmao_index_153915944934 1 p STARTED 39931 4.1mb 172.17.0.14 35S66p1tenmao_index_153915944934 1 r STARTED 39931 4mb 172.17.0.3 DPKsmMNtenmao_index_153915944934 0 p STARTED 39634 4mb 172.17.0.2 PE8QHxztenmao_index_153915944934 0 r STARTED 39634 4mb 172.17.0.3 DPKsmMN 分片中如果存在未分配的分片， 可以查看未分片的原因：_cat/shards?h=index,shard,prirep,state,unassigned.reason&amp;v 索引索引管理 索引列表 123curl -X GET &quot;localhost:9200/_cat/indices?v&quot;health status index uuid pri rep docs.count docs.deleted store.size pri.store.sizegreen open tenmao_index_153915944934 Z6BV1VaMRc-tC-7IucJE2w 5 1 198444 0 40.9mb 20.4mb 条件过滤：_cat/indices?v&amp;health=yellow 排序：_cat/indices?v&amp;health=yellow&amp;s=docs.count:desc 索引详细信息 1curl -X GET &quot;localhost:9200/chat_index_alias/_stats?pretty&quot; 数据量 1curl -X GET &quot;localhost:9200/_cat/count/chat_index_alias?v&amp;pretty&quot; 新建索引 123456789curl -X PUT &quot;localhost:9200/my_index&quot; -d &#x27;&#123; &quot;settings&quot; : &#123; &quot;index&quot; : &#123; &quot;number_of_shards&quot; : 3, &quot;number_of_replicas&quot; : 2 &#125; &#125;&#125;&#x27; 删除索引 123curl -X DELETE &quot;localhost:9200/tenmao_index&quot;curl -X DELETE &quot;localhost:9200/tenmao_index_1504520299944&quot; 索引使用 分词搜索 12345678curl -X POST &quot;localhost:9200/chat_index_alias/_search&quot; -d &#x27;&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;question&quot;: &quot;吃饭了吗&quot; &#125; &#125;&#125;&#x27; 完全匹配搜索 12345678curl -X POST &quot;localhost:9200/chat_index_alias/_search&quot; -d &#x27;&#123; &quot;query&quot;: &#123; &quot;match_phrase&quot;: &#123; &quot;question&quot;: &quot;你吃饭了&quot; &#125; &#125;&#125;&#x27; 别名 查看别名 1curl -X GET &quot;localhost:9200/_alias/chat_index_alias?pretty&quot; 增加别名 1curl -X PUT &quot;localhost:9200/my_index/_alias/my_index_alias?pretty&quot; 删除别名 123456curl -X POST &#x27;http://localhost:9200/_aliases&#x27; -d &#x27;&#123; &quot;actions&quot;: [ &#123;&quot;remove&quot;: &#123;&quot;index&quot;: &quot;my_index&quot;, &quot;alias&quot;: &quot;my_index_alias&quot;&#125;&#125; ]&#125;&#x27; 一般纯删除别名使用的比较少，一般是别名重新绑定（删除和绑定为一个原子操作） 别名重新绑定 1234567curl -XPOST &#x27;http://localhost:9200/_aliases&#x27; -d &#x27;&#123; &quot;actions&quot; : [ &#123; &quot;remove&quot; : &#123; &quot;index&quot; : &quot;my_index&quot;, &quot;alias&quot; : &quot;my_index_alias&quot; &#125; &#125;, &#123; &quot;add&quot; : &#123; &quot;index&quot; : &quot;my_index_v2&quot;, &quot;alias&quot; : &quot;my_index_alias&quot; &#125; &#125; ]&#125;&#x27;","categories":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"http://www.postman.life/categories/ElasticSearch/"}],"tags":[]},{"title":"Linux常用命令","slug":"Linux常用命令","date":"2021-06-13T18:18:15.000Z","updated":"2021-06-14T13:59:51.355Z","comments":true,"path":"2021/06/14/Linux常用命令/","link":"","permalink":"http://www.postman.life/2021/06/14/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","excerpt":"","text":"前言本文特点 授之以渔：了解命令学习方法、用途：不再死记硬背，拒绝漫无目的； 准确无误：所有命令执行通过（环境为centos7），拒绝复制粘贴； 实用性高：命令多为实际工作中用到的，实例讲解，拒绝纯理论； 条理清晰：分类归纳，快速找到想要的命令，拒绝天马行空； 总结性强：只列常用语法，易错情况强调，拒绝照搬照套。 学前须知 适用人群：开发、测试、运维等等 文档用途：linux入门学习、命令备忘录、面试复习 学习途径：书籍（鸟哥的Linux私房菜）、视频：慕课网等、百度谷歌搜索、qq群等 学习环境：虚拟机VirtualBox+centos7 学习记录：多动手，多联想，多记录，特别是遇到问题时 遇到问题：百度谷歌搜索、系统日志（/var/log/）、qq群 学前理论 linux主要特征 ：一切且文件（目录、硬盘等都是文件）；硬件都在/dev 目录，如硬盘、U盘为/dev/sd[a-d]； /dev/sr0（/dev/cdrom）是光驱的设备名（df命令查看），为设备文件，代表的是光驱本身，得把这个设备挂载到目录下（一般为/mnt）(文件系统的临时挂载点)，才能对设备上的文件进行读写等操作； 不懂的命令 ：man 命令（查用法、全称），只记得关键词，可用man -k 关键词； Linux命令常用结构 ：Command [-option] [argument]Command：即是要运行的命令的本身，说白了就是一个软件（程序）；Option：是选项（可选），选项是控制命令运行状态和行为的（可多个选项一起，如df -hT）；Argument：是参数（可选），是命令要操作对象如文件、路径、数据、目录等；在指令的第一部分按[tab]键一下为[命令补全]，两下为所有命令选择，在非第一部分按[tab]键两下为[文件补全]； linux命令区分大小写； 开关机 sync ：把内存中的数据写到磁盘中（关机、重启前都需先执行sync） shutdown -r now或reboot ：立刻重启 shutdown -h now ：立刻关机 shutdown -h 20:00 ：预定时间关闭系统（晚上8点关机，如果现在超过8点，则明晚8点） shutdown -h +10 ：预定时间关闭系统（10分钟后关机） shutdown -c ：取消按预定时间关闭系统 系统信息 who am i ：查看当前使用的终端 who 或 w ： 查看所有终端 uname -m ：显示机器的处理器架构（如x86_64） cat /proc/version ：查看linux版本信息 uname -r ：显示正在使用的内核版本 lsb_release -a ：查看系统发行版本（如CentOS7）（没这个命令先安装yum install -y redhat-lsb-core） rpm -qa | grep kernel-devel ：查看kernel-devel版本（安装软件时编译内核用，故需要保持内核版本一致性） **yum install -y “kernel-devel-uname-r == $(uname -r)”**：安装和Linux内核版本匹配的kernel-devel hostnamectl set-hostname 主机名：修改主机名（包括静态、瞬态和灵活主机名，如有域名解析记得手动更新/etc/hosts） date ：显示系统日期 （date +%Y/%m/%d : 显示效果如2018/01/01） date 070314592018.00 ：设置时间（格式为月日时分年.秒 ） clock -w ：将时间修改保存到 BIOS cal 2018 ：显示2018年的日历表 clear ：清空命令行 ifconfig ：显示或设置网卡（查ip等）（类似windows中ipconfig） ping -c 3 www.baidu.com ：测试百度与本机的连接情况（ -c 3表示测试3次） cat /proc/cpuinfo ：显示CPU的信息 cat /proc/cpuinfo| grep “physical id”| sort| uniq| wc -l ：查看物理CPU个数 cat /proc/cpuinfo| grep “cpu cores”| uniq ：查看每个物理CPU的核数 cat /proc/cpuinfo| grep “processor”| wc -l ：查看逻辑CPU个数即线程数 系统性能 top ：动态实时显示cpu、内存、进程等使用情况（类似windows下的任务管理器） top -d 2 -p 7427 ：-d为画面更新的秒数，默认5秒，-p为指定进程pid的信息 vmstat 2 10 ：每隔2秒采集一次服务器状态，采集10次（查看内存、io读写状态、cpu） free -h :查看系统内存及虚拟内存使用情况 df -h :显示磁盘的空间使用情况 iostat ：可查io读写、cpu使用情况 sar -u 3 5 :查看cpu使用情况（3秒一次，共5次） sar -d 2 3 ：评估磁盘性能 ps aux|grep firefox ：获取火狐的进程号（PID）（可查看进程占用cpu、内存百分比及进程触发指令的路径） kill -9 进程号 ：强制杀死进程 systemctl ：查看正在运行的服务 文件和目录 cd:是Change Directory的缩写，用来切换工作目录，语法：cd [相对或绝对路径或特殊符号] cd ：进入该用户的主目录 ~（root用户为/root,其他用户为/home/用户名） cd .. ：返回上一级目录（注意要空格） cd - ：返回上次所在目录 cd / ：返回根目录 （绝对路径） cd ./目录1/目录2 ：进入当前目录下的子目录（相对路径） pwd ：显示工作路径（Print Working Directory 的缩写） ls:是List的缩写，用于列出目录下的文件，语法：ls [选项][目录或文件名] ls -a :列出文件下所有的文件，包括以“.“开头的隐藏文件 *ls -lh .log :列出文件的详细信息（.log结尾，*为通配符代表任意多个字符） file 文件或目录 ：显示文件的类型（目录、text、zip、shell脚本等） mkdir dir1 :创建目录(dir1)（mkdir为make directory的缩写） mkdir -p ./dir1/dir2 :递归创建目录（-p：父目录不存在时，同时建立） touch a.txt :创建文件a.txt rm:可以删除一个目录中的一个或多个文件或目录，也可以将某个目录及其下属的所有文件及其子目录均删除掉; 语法：rm (选项)(参数)（注：如果参数中含有目录，则必须加上-r选项）； rm 文件 ：删除文件 rm -r 目录或文件 ：删除目录（及目录下所有文件）（非空也可以） rm -rf 目录或文件 ：强制删除，如：rm -rf * 为删除当前目录下所有文件 find -inum 1842601 -exec rm -rf {} ; ：删除乱码文件或目录(会提示找不到此文件或文件夹但其实已经删除了)（上传中文文件会乱码，rm命令删除不了）（先使用ls -i命令找到inode，即文件或目录前面的数字字符串,如1842601;） mv：是move的缩写，可以用来剪切移动文件、目录或者将文件改名； 语法：mv 源文件 目标文件（改名）或目录（移动）； mv a b :移动或者重命名一个文件或者目录（存在即移动目录或覆盖文件，不存在即改名） mv /opt/git/g /opt/a ：移动g到opt目录下并改名为a（a目录不存在，若存在则为移动g到a目录下） mv -t ./test a.txt b.txt ：移动多个文件到某目录下 cp:复制文件或目录；cp命令可以将单个或多个文件复制到一个已经存在的目录下； 常用：cp -ai 文件或目录 目标目录; cp -ai /opt/abc /opt/git/ ：复制abc目录（或文件）到git目录下（选项a表示文件的属性也复制、目录下所有文件都复制；i表示覆盖前询问） ln：link的缩写，用于建立硬（软）链接，常用于软件安装时建软链接(类似快捷方式)到PATH; 语法：ln [-s] 源文件 目标文件 ln -s /opt/a.txt /opt/git/ :对文件创建软链接（快捷方式不改名还是a.txt） ln -s /opt/a.txt /opt/git/b :（快捷方式改名为b）（下面的一样可以改名） ln -s /opt/mulu /opt/git/ :对目录创建软链接 ln /opt/a.txt /opt/git/ :对文件创建硬链接 文件权限 chmod [-R] 777文件或目录 ：设置权限（chmod a+rwx a=chmod ugo +rwx a=chmod 777 a） 注： r（read）对应4，w（write）对应2，x（execute）执行对应1；-R：递归更改文件属组，就是在更改某个目录文件的属组时，如果加上-R的参数，那么该目录下的所有文件的属组都会更改） chmod [{ugoa}{+-=}{rwx}][文件或目录] ：如chmod u-w,g+x,o=r test.txt为user（拥有者）去掉写权限，group(所属组)加上执行权限，other(其他人)权限等于只读； chown [-R] admin:root /opt/ ：变更文件及目录的拥有者和所属组（-R递归处理所有文件和文件夹，admin为拥有者，root为所属者） 文件查找 locate a.txt ：在系统全局范围内查找文件名包含a.txt字样的文件（比find快）; locate:原理是updatedb会把文件系统中的信息存放到数据库databases中（但一般一天才执行一次，所以locate找不到新创建的文件，需要先手动执行updatedb，再执行locate）,locate从数据库中读数据; find：在目录结构中搜索文件，并执行指定的操作 语法：find pathname -options [-print -exec …] pathname ：为 find命令所查找的目录路径。例如用.来表示当前目录，用/来表示系统根目录（find查找范围为目标目录及其子目录所有文件及目录）； -exec： find命令对匹配的文件执行该参数所给出的shell命令。相应命令的形式为’command’ { } ;，注意{ }和\\；之间的空格； -print： find命令将匹配的文件输出到标准输出； find /home -mtime -2 ：在/home下查最近2*24小时内改动过的文件 find . -size +100M ：在当前目录及子目录下查找大于100M的文件 find . -type f ：f表示文件类型为普通文件（b/d/c/p/l/f 分别为块设备、目录、字符设备、管道、符号链接、普通文件） find . -mtime +2 -exec rm {} ; :查出更改时间在2*24小时以前的文件并删除它** find . -name ‘*.log’ -exec grep -i hello {} ; -print :在当前目录及子目录下查出文件名后缀为.log的文件并且该文件内容包含了hello字样并打印，-exec 命令 {} \\表示对查出文件操作，-i表示不区分大小写； find . -name ‘*.log’|grep hello :在当前目录及子目录下查出文件名后缀为.log的文件并且文件名包含了hello字样（grep用来处理字符串）； grep -i ‘HELLO’ . -r -n ：在当前目录及子目录下查找文件内容中包含hello的文件并显示文件路径（-i表示忽略大小写） which java ：在环境变量$PATH设置的目录里查找符合条件的文件，并显示路径（查询运行文件所在路径） whereis java :查看安装的软件的所有的文件路径（whereis 只能用于查找二进制文件、源代码文件和man手册页，一般文件的定位需使用locate命令） 拷贝文件 cp -r /usr/iais-files/backupsAudit /root/iais-files/backups 删除文件 rm -rf backupsAudit 文件夹查找 find / -name ‘backupsAudit’ -type d 查看文件的内容 cat [-n] 文件名 :显示文件内容，连行号一起显示 less 文件名 ：一页一页的显示文件内容（搜索翻页同man命令） head [-n] 文件名 ：显示文件头n行内容，n指定显示多少行 tail [-nf] 文件名:显示文件尾几行内容,n指定显示多少行,f用于实时追踪文件的所有更新，常用于查阅正在改变的日志文件（如tail -f -n 3 a.log 表示开始显示最后3行，并在文件更新时实时追加显示，没有-n默认10行） sed -n ‘2,$p’ ab ：显示第二行到最后一行； sed -n ‘/搜索的关键词/p’ a.txt ：显示包括关键词所在行 less a.txt |grep 搜索的关键词 ：显示包括关键词所在行 cat -n a.txt |grep 搜索的关键词 ：显示包括关键词所在行（连行号一起显示） cat filename |grep abc -A10 ：查看filename中含有abc所在行后10行（A10）、前10行（B10）内容 less a.txt|grep git ：显示关键词所在行，管道符”|”它只能处理由前面一个指令传出的正确输出信息，对错误信息信息没有直接处理能力。然后传递给下一个命令，作为标准的输入； cat /etc/passwd |awk -F ‘:’ ‘{print $1}’ ：显示第一列 文本处理 ls -l&gt;file ：输出重定向&gt;（改变原来系统命令的默认执行方式）：ls -l命令结果输出到file文件中，若存在，则覆盖 cat file1 &gt;&gt;file ：输出重定向之cat命令结果输出追加到file文件(&gt;表示覆盖原文件内容，&gt;&gt;表示追加内容) ls fileno 2&gt;file ： 2&gt;表示重定向标准错误输出（文件不存在，报错信息保存至file文件）； cowsay &lt;a.txt :重定向标准输入’命令&lt;文件’表示将文件做为命令的输入（为从文件读数据作为输入） sed -i ‘4,$d’ a.txt ：删除第四行到最后一行（$表示最后一行）（sed可以增删改查文件内容） sed -i ‘$a 增加的字符串’ a.txt ：在最后一行的下一行增加字符串 sed -i ‘s/old/new/g’ a.txt :替换字符串；格式为sed ‘s/要替换的字符串/新的字符串/g’ 修改的文件 grep -o ‘关键词’ test.log|wc -l :统计某个关键词在某个文件中出现的次数（如出现3次输出3） vim 文件：编辑查看文件（同vi） 用户与权限 useradd 用户名 ：创建用户 userdel -r 用户名 :删除用户：（-r表示把用户的主目录一起删除） usermod -g 组名 用户名 ：修改用户的组 usermod -aG 组名 用户名 ：将用户添加到组 groups test ：查看test用户所在的组 cat /etc/group |grep test ：查看test用户详情：用户名:口令:用户标识号:组标识号:注释性描述:主目录:登录Shell passwd [ludf] 用户名 ：用户改自己密码，不需要输入用户名，选项-d:指定空口令,-l:禁用某用户，-u解禁某用户，-f：强迫用户下次登录时修改口令 groupadd 组名 ：创建用户组 groupdel 用户组 ：删除组 groupmod -n 新组名 旧组名 ：修改用户组名字 su - 用户名：完整的切换到一个用户环境（相当于登录）（建议用这个）（退出用户：exit） su 用户名 :切换到用户的身份（环境变量等没变，导致很多命令要加上绝对路径才能执行） sudo 命令 ：以root的身份执行命令（输入用户自己的密码，而su为输入要切换用户的密码，普通用户需设置/etc/sudoers才可用sudo） SSH 免密登录 ： 1234567891011#使用OpenSSH生成密钥ssh-keygen -t rsa#公钥信息写入authorized_keys文件中并设置权限cd ~/.sshcat id_rsa.pub &gt;&gt; authorized_keyschmod 700 ~/.sshchmod 600 ~/.ssh/authorized_keys#生成putty的私钥（Putty使用的私钥格式和OpenSSH生成的有点不同，需要转换一下putty才能使用）把私钥id_rsa下载到本地后后缀改成.ppk，如id_rsa_ip_commonuser.ppk使用puttygen工具的“Load”读取id_rsa文件，点击“Save private key”保留私钥；putty关联私钥文件即可登陆服务器 磁盘管理 fdisk -l :查看磁盘信息(可查各个硬盘容量大小、可查各硬盘分区情况)（各硬盘或硬盘下分区必须挂载到某个目录才能被使用） fdisk /dev/sdb :对硬盘sdb创建分区 mkfs.ext4 /dev/vdb1 :修改格式化硬盘分区vdb1的文件系统类型为ext4 df -TH :显示磁盘的空间使用情况、文件系统类型、挂载点（硬盘挂载了才会显示） df -h /var/log :（显示log所在分区（挂载点）、目录所在磁盘及可用的磁盘容量） *du -sm /var/log/ | sort -rn** : 根据占用磁盘空间大小排序（MB）某目录下文件和目录大小 mount /dev/sda1 /mnt ：硬盘sda1挂载到/mnt目录（mount 装置文件名 挂载点） mount -t cifs -o username=luolanguo,password=win用户账号密码,vers=3.0 //10.2.1.178/G /mnt/usb :远程linux 共享挂载windows的U盘,G为U盘共享名，需设置U盘共享 mount -o loop /opt/soft/CentOS-7-x86_64-DVD-1708.iso /media/CentOS ：挂载iso文件 umount /dev/sda1 ：取消挂载（umount 装置文件名或挂载点） 压缩、解压和打包备份 单纯tar仅为打包（多个文件包成一个大文件），加上参数-j(bzip2格式.bz2)、-z（gzip格式.gz）可以备份、压缩(-c)、解压（-x），备份一般比压缩多加参数-p（保留原本文件的权限与属性），-C可以指定解压到特定目录；bzip2、gzip只能对单一文件压缩； file 文件名 ：查文件类型（可看是用哪一种方式压缩的） tar -zxvf a.tar.gz -C ./test ：解压tar.gz到当前目录下的test目录 tar -zcvf /opt/c.tar.gz ./a/ ：压缩tar.gz（把当前目录下的a目录及目录下所有文件压缩为 /opt/目录下的c.tar.gz，这样tar -zxvf c.tar.gz解压出来带有目录a） tar -jxvf a.tar.bz2 ：解压tar.bz2（到当前目录） tar -jcvf c.tar.bz2 ./a/ ：压缩tar.bz2（把当前目录下的a目录及目录下所有文件压缩到当前目录下为c.tar.gz2） unzip a.zip ：解压zip（到当前目录） unzip -o mdmtest.war -d /opt/mdm ：推荐使用unzip解压war包（-o覆盖原有文件，-d指定文件解压后存储的目录） zip -r c.zip ./a/ :压缩zip(把当前目录下的a目录及目录下所有文件压缩到当前目录下为c.zip bzip2 -k file1 ： 压缩一个 ‘file1’ 的文件（-k表示保留源文件）（bzip2格式，比gzip好） bzip2 -d -k file1.bz2 ： 解压一个叫做 ‘file1.bz2’的文件 gzip file1 ： 压缩一个叫做 ‘file1’的文件（gzip格式）（不能保留源文件） gzip -9 file1 ： 最大程度压缩 gzip -d file1.gz ： 解压缩一个叫做 ‘file1’的文件 软件安装 尽量用yum源（apt-get）安装，不行就rpm、deb包安装，能不手动编译的就不要手动编译； dpkg只能安装已经下载到本地机器上的deb包. apt-get能在线下载并安装deb包,能更新系统,且还能自动处理包与包之间的依赖问题,这个是dpkg工具所不具备的； rpm 只能安装已经下载到本地机器上的rpm 包. yum能在线下载并安装rpm包,能更新系统,且还能自动处理包与包之间的依赖问题,这个是rpm 工具所不具备的; yum、rpm安装文件分布在/usr的bin、lib、share不同目录，不用配置PATH，直接用命令，但可用命令卸载更新； 手动编译软件，默认位置为/usr/local下不同子目录下,不用配置PATH直接用命令（手动指定安装路径需要加PATH），使得软件更新和删除变得很麻烦。编译安装的软件没有卸载命令，卸载就是把所有这个软件的文件删除。 二进制(Binaries)包yum安装 在线下载并安装rpm包，适用于CentOS、Fedora、RedHat及类似系统 yum install epel-releas ：安装第三方yum源EPEL（企业版 Linux 附加软件包的简称） yum repolist enabled ：显示可用的源仓库（/etc/yum.repos.d/目录下配置） yum install yum-fastestmirror ：自动选择最快的yum源 yum list installed |grep java ：列出已安装的软件（查看已安装的JDK） yum remove java-1.8.0-openjdk.x86_64 ：卸载软件（卸载JDK） *yum list java ** ：列出已安装和可安装的软件（查看yum库中的JDK包） yum install [-y] java-1.8.0-openjdk ：安装软件JDK(-y自动安装)（推荐这种方式安装） yum install docker-ce-18.03.1.ce ：安装指定版本的软件（已知docker-ce.x86_64 18.03.1.ce-1.el7.centos，则rpm包名为docker-ce-18.03.1.ce-1.el7.centos.x86_64.rpm） **yum check-update [kernel] ** ：列出所有可更新的软件（检查更新kernel） yum update tomcat ：更新软件（可所有） rpm -ql 软件名称 ：查询yum安装路径（软件名称可通过rpm -qa|grep java） yum info kernel ：查看软件（kernel）的信息 yum clean all ：（清除缓存，使最新的yum配置生效） yum安装常用工具 yum install -y unzip zip ：安装压缩、解压缩命令（zip、unzip） rpm包手动下载安装 yum中没有时用，适用于CentOS、Fedora、RedHat及类似系统； wget -P /opt https://网址 ：下载到/opt目录 rpm -ivh wps-office-版本.x86_64.rpm :安装rpm包（包要先下载）（要先装依赖包） rpm -e wps-office ：卸载软件（注意不要软件名不要版本号） rpm -qa |grep wps ：查看安装的rpm包（可用于查询rpm包是否被安装） rpm -ql 软件名称 ：查看rpm包安装路径（软件名称可通过rpm -qa|grep java） apt方式安装 安装deb包，类似yum安装，适用于Debian, Ubuntu 以及类似系统； apt-get install aptitude ：安装aptitude工具,实现依赖自动安装，依赖版本自动降级或升级 aptitude install 软件 ：安装软件（推荐这种方式安装） apt-cache search 软件 ：搜索软件 apt-get install 软件 ：安装软件 apt-get purge 软件 ：卸载软件（包括配置文件，只删除软件purge换成remove） apt-get upgrade ：更新所有已安装的软件包 apt-get update ：升级列表中的软件包 apt-get clean ：从下载的软件包中清理缓存 deb包安装 适用于Debian, Ubuntu 以及类似系统； dpkg -i package.deb ：安装一个 deb 包 dpkg -r package_name ：从系统删除一个 deb 包 dpkg -l |grep chrome ：查询系统中所有已经安装的 deb 包 dpkg -L 软件名称 ：查软件安装的文件 解压即用 大多数非开源的商业软件都采取这种办法； 二进制（Binaries）包如apache-jmeter-3.3.tgz，下载复制解压到/opt，然后然后将该软件的 bin 目录加入到 PATH 中即可（vim /etc/profile export PATH=$PATH:/opt/apache-jmeter-3.3/bin）； 软件自己的模块/包管理器 如python：系统的源中不可能包含该软件的所有模块； 系统的源中该软件的模块的更新要远远滞后于最新版本；手动安装python，并用Python 自带的 pip 安装模块（类似yum）； **pip install redis ** ：安装python软件包redis **pip unstall redis ** :卸载 **pip show –files redis ** :pip查看已安装的包 pip list –outdated :检查更新 源代码(Source)包编译安装 源代码包（一般有install文件）如hello-2.2.tar.bz2，下载复制到/opt; tar -jxvf hello-2.2.tar.bz2 :解压 ./configure –prefix=/opt/软件目录名称 :为编译做好准备，加上 prefix 手动指定安装路径 make ：编译 make install ：安装 make clean ：删除安装时产生的临时文件 vim /etc/profile export PATH=$PATH:/opt/目录/bin ：手动指定安装路径需要加path hello ：执行软件：看INSTALL和README文件（是否源码包、如何安装、执行都看这两个） rm -rf 软件目录名称 :卸载软件 服务与进程 netstat -ntlp :查看服务器所有被占用端口 netstat -lnp|grep 端口号/进程号/进程名 :根据查端口是否打开确认服务是否启动，配合ps命令可查服务占用的端口常用参数：-p：获取进程名、进程号；-n：禁用域名解析功能，查出IP且速度快；-l：只列出监听中的连接；-t：只列出 TCP协议的连接。示例：ps aux|grep tomcat netstat -lnp|grep 进程号 ：查tomcat服务占用的端口； ps aux|grep 进程号/进程启动命令/服务名 :进程查看命令ps(可查进程状态；进程占用cpu、内存；配合netstat根据某服务端口查出进程号用于杀进程，查服务启动命令及服务路径 ） 查看文本cat：从第一行开始显示全部的文本内容；tac：从最后一行开始，显示全部分文本内容，与cat相反；nl:显示文本时，可以输出行号；more:按页显示文本内容；less:与more差不多，也是按页显示文本内容，区别是less可以一行一行的回退，more回退只能一页一页回退；head:从头开始显示文件指定的行数；tail:显示文件指定的结尾的行数，但每一行的位置还是原文件中的位置，不会像tac那样与原文件相反。vi: NB的Linux文本编辑器。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://www.postman.life/categories/Linux/"}],"tags":[]},{"title":"Debian下Bochs安装记录","slug":"Debian下Bochs安装记录","date":"2021-06-13T15:31:08.000Z","updated":"2021-06-14T14:20:30.055Z","comments":true,"path":"2021/06/13/Debian下Bochs安装记录/","link":"","permalink":"http://www.postman.life/2021/06/13/Debian%E4%B8%8BBochs%E5%AE%89%E8%A3%85%E8%AE%B0%E5%BD%95/","excerpt":"","text":"下载地址 address:https://sourceforge.net/projects/bochs/files/bochs/2.6.9/ 安装Bochs第一种安装方式，需要编译下载 curl -O https://nchc.dl.sourceforge.net/project/bochs/bochs/2.6.9/bochs-2.6.9.tar.gz 解压 tar -zxvf bochs-2.6.9.tar.gz cd进入目录 cd bochs-2.6.9 配置编译选项 ./configure –with-x11 –with-wx –enable-debugger –enable-disasm –enable-all-optimizations –enable-readline –enable-long-phy-address –enable-ltdl-install –enable-idle-hack –enable-plugins –enable-a20-pin –enable-x86-64 –enable-smp –enable-cpu-level=6 –enable-large-ramfile –enable-repeat-speedups –enable-fast-function-calls –enable-handlers-chaining –enable-trace-linking –enable-configurable-msrs –enable-show-ips –enable-cpp –enable-debugger-gui –enable-iodebug –enable-logging –enable-assert-checks –enable-fpu –enable-vmx=2 –enable-svm –enable-3dnow –enable-alignment-check –enable-monitor-mwait –enable-avx –enable-evex –enable-x86-debugger –enable-pci –enable-usb –enable-voodoo MakeFile配置完之后输入make命令编译 1make 报错解决方法 1make: *** No rule to make target &#x27;misc/bximage.cc&#x27;, needed by &#x27;misc/bximage.o&#x27;. Stop. 解决方案为： 1cp misc&#x2F;bximage.cpp misc&#x2F;bximage.cc 接下来还有类似的No rule to make target ‘xxxx’，解决方案类似。 12345cp iodev/hdimage/hdimage.cpp iodev/hdimage/http://hdimage.cccp iodev/hdimage/vmware3.cpp iodev/hdimage/http://vmware3.cccp iodev/hdimage/vmware4.cpp iodev/hdimage/http://vmware4.cccp iodev/hdimage/vpc-img.cpp iodev/hdimage/http://vpc-img.cccp iodev/hdimage/vbox.cpp iodev/hdimage/http://vbox.cc make执行成功后，安装 make install 第二种安装方式，我选择的123apt-get install bochsapt-get install bochs-x 安装完成之后，配置会在/etc/bochs-init 目录下 我们可以看看 目录下包含了哪些文件 1bochsrc init.sh 以及/usr/local/share/bochs/目录下包含了哪些文件 1234bios.bin-1.7.5 SeaBIOS-README VGABIOS-lgpl-latest-cirrusBIOS-bochs-latest VGABIOS-elpin-2.40 VGABIOS-lgpl-latest-cirrus-debugBIOS-bochs-legacy VGABIOS-elpin-LICENSE VGABIOS-lgpl-latest-debugkeymaps VGABIOS-lgpl-latest VGABIOS-lgpl-README 需要稍微对这两个目录下的文件作一点说明。/etc/bochs-init/目录里的bochsrc是bochs的配置文件，这是一个很重要的文件，它必须设置准备否则无法运行bochs，这个我们等会还需要进一步地讲解bochsrc文件；/usr/local/share/bochs/目录里的几个文件是bochs在加载内核image时的bios引导用的模拟程序，也就是说当bochs想要运行bochs时，内核image的引导过程是由这个目录中的BIOS-bochs-latest和BIOS-bochs-legacy来完成的。 如果运行bochs出现错误: display library ‘sdl’ not available 只需要将bochs配置文件bochrc中display_library:sdl删除或者改成x即可 bochsrc 配置文件 config_interface: textconfigdisplay_library : xromimage: file=/usr/share/bochs/BIOS-bochs-latestboot:floppymegs: 32vgaromimage: file=/usr/share/vgabios/vgabios.binfloppya:type=1_44, 1_44=”/etc/bochs-init/boot.img”, status=insertedata0: enabled=1, ioaddr1=0x1f0, ioaddr2=0x3f0, irq=14ata1: enabled=0, ioaddr1=0x170, ioaddr2=0x370, irq=15ata2: enabled=0, ioaddr1=0x1e8, ioaddr2=0x3e0, irq=11ata3: enabled=0, ioaddr1=0x168, ioaddr2=0x360, irq=9#ata0-master: type=disk, path=””, mode=flat, cylinders=1024, heads=16, spt=63ata0-slave: type=cdrom, path=”/dev/cdrom”, status=inserted boot:floppy #ips: 1000000floppy_bootsig_check: disabled=0log: /dev/stdoutpanic: action=askerror: action=reportinfo: action=reportdebug: action=ignoredebugger_log: -com1: enabled=1, dev=/dev/ttyS0parport1: enabled=1, file=”/dev/lp0”sb16: midimode=1, midi=/dev/midi00, wavemode=1, wave=/dev/dsp, loglevel=2, log=/dev/stdout, dmatimer=600000#vga_update_interval: 300000#keyboard_serial_delay: 250#keyboard_paste_delay: 100000#floppy_command_delay: 500mouse: enabled=0#private_colormap: enabled=0#ne2k: ioaddr=0x240, irq=9, mac=b0:c4:20:00:00:00, ethmod=linux, ethdev=eth0#keyboard_mapping: enabled=0, map=/usr/share/bochs/keymaps/x11-pc-de.map#keyboard_type: mf#user_shortcut: keys=ctrlaltdel#magic_break: enabled=1#cmosimage: cmos.img#load32bitOSImage: os=nullkernel, path=../kernel.img, iolog=../vga_io.log#load32bitOSImage: os=linux, path=../linux.img, iolog=../vga_io.log, initrd=../initrd.img#i440fxsupport: enabled=1#usb1: enabled=1, ioaddr=0xFF80, irq=10#text_snapshot_check: enable Img引导启动软盘制作安装了bochs后，该软件提供一个bximage工具可以制作img文件。 制作步骤如下： bximage -&gt; [1] -&gt; 1.44M -&gt; boot.img","categories":[{"name":"Linux","slug":"Linux","permalink":"http://www.postman.life/categories/Linux/"},{"name":"Bochs","slug":"Linux/Bochs","permalink":"http://www.postman.life/categories/Linux/Bochs/"}],"tags":[]},{"title":"Spring笔记","slug":"spring-application","date":"2021-05-25T16:22:10.000Z","updated":"2021-05-25T16:29:06.020Z","comments":true,"path":"2021/05/26/spring-application/","link":"","permalink":"http://www.postman.life/2021/05/26/spring-application/","excerpt":"","text":"Spring笔记BeanFactory和ApplicationContext之间的关系 BeanFactory和ApplicationContext是Spring的两大核心接口，而其中ApplicationContext是BeanFactory的子接口。它们都可以当做Spring的容器，Spring容器是生成Bean实例的工厂，并管理容器中的Bean。在基于Spring的Java EE应用中，所有的组件都被当成Bean处理，包括数据源，Hibernate的SessionFactory、事务管理器等。 生活中我们一般会把生产产品的地方称为工厂，而在这里bean对象的地方官方取名为BeanFactory，直译Bean工厂（com.springframework.beans.factory.BeanFactory），我们一般称BeanFactory为IoC容器，而称ApplicationContext为应用上下文。 Spring的核心是容器，而容器并不唯一，框架本身就提供了很多个容器的实现，大概分为两种类型：一种是不常用的BeanFactory，这是最简单的容器，只能提供基本的DI功能；一种就是继承了BeanFactory后派生而来的ApplicationContext(应用上下文)，它能提供更多企业级的服务，例如解析配置文本信息等等，这也是ApplicationContext实例对象最常见的应用场景。 容器环境Standalone XML application context (ClassPathXmlApplicationContext) 类图 12345ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(&quot;spring/dubbo-consumer.xml&quot;);context.start();DemoService demoService = context.getBean(&quot;demoService&quot;, DemoService.class);String hello = demoService.sayHello(&quot;world&quot;);System.out.println(&quot;result: &quot; + hello); DefaultListableBeanFactory类图 BeanFactoryBeanFactory 是 Spring 的“心脏”。它就是 Spring IoC 容器的真面目。Spring 使用 BeanFactory 来实例化、配置和管理 Bean。 BeanFactory：是IOC容器的核心接口， 它定义了IOC的基本功能，我们看到它主要定义了getBean方法。getBean方法是IOC容器获取bean对象和引发依赖注入的起点。方法的功能是返回特定的名称的Bean。 BeanFactory基本的类体系结构，这里没有包括强大的ApplicationContext体系。具体： 1、BeanFactory作为一个主接口不继承任何接口，暂且称为一级接口。 2、有3个子接口继承了它，进行功能上的增强。这3个子接口称为二级接口。 3、ConfigurableBeanFactory可以被称为三级接口，对二级接口HierarchicalBeanFactory进行了再次增强，它还继承了另一个外来的接口SingletonBeanRegistry 4、ConfigurableListableBeanFactory是一个更强大的接口，继承了上述的所有接口，无所不包，称为四级接口。 （这4级接口是BeanFactory的基本接口体系。继续，下面是继承关系的2个抽象类和2个实现类：） 5、AbstractBeanFactory作为一个抽象类，实现了三级接口ConfigurableBeanFactory大部分功能。 6、AbstractAutowireCapableBeanFactory同样是抽象类，继承自AbstractBeanFactory，并额外实现了二级接口AutowireCapableBeanFactory 7、DefaultListableBeanFactory继承自AbstractAutowireCapableBeanFactory，实现了最强大的四级接口ConfigurableListableBeanFactory，并实现了一个外来接口BeanDefinitionRegistry，它并非抽象类。 8、最后是最强大的XmlBeanFactory，继承自DefaultListableBeanFactory，重写了一些功能，使自己更强大。 总结： BeanFactory的类体系结构看似繁杂混乱，实际上由上而下井井有条，非常容易理解。 1234567891011121314151617181920212223242526272829303132public interface BeanFactory &#123; /** * 用来引用一个实例，或把它和工厂产生的Bean区分开，就是说，如果一个FactoryBean的名字为a，那么，&amp;a会得到那个Factory */ String FACTORY_BEAN_PREFIX = &quot;&amp;&quot;; /* * 四个不同形式的getBean方法，获取实例 */ Object getBean(String name) throws BeansException; &lt;T&gt; T getBean(String name, Class&lt;T&gt; requiredType) throws BeansException; &lt;T&gt; T getBean(Class&lt;T&gt; requiredType) throws BeansException; Object getBean(String name, Object... args) throws BeansException; boolean containsBean(String name); // 是否存在 boolean isSingleton(String name) throws NoSuchBeanDefinitionException;// 是否为单实例 boolean isPrototype(String name) throws NoSuchBeanDefinitionException;// 是否为原型（多实例） boolean isTypeMatch(String name, Class&lt;?&gt; targetType) throws NoSuchBeanDefinitionException;// 名称、类型是否匹配 Class&lt;?&gt; getType(String name) throws NoSuchBeanDefinitionException; // 获取类型 String[] getAliases(String name);// 根据实例的名字获取实例的别名&#125; 具体： 1、4个获取实例的方法。getBean的重载方法。 2、4个判断的方法。判断是否存在，是否为单例、原型，名称类型是否匹配。 3、1个获取类型的方法、一个获取别名的方法。根据名称获取类型、根据名称获取别名。一目了然！总结： 这10个方法，很明显，这是一个典型的工厂模式的工厂接口。 BeanFactory最常见的实现类为XmlBeanFactory，可以从classpath或文件系统等获取资源。 123File file = new File(&quot;fileSystemConfig.xml&quot;);Resource resource = new FileSystemResource(file);BeanFactory beanFactory = new XmlBeanFactory(resource); 12Resource resource = new ClassPathResource(&quot;classpath.xml&quot;); BeanFactory beanFactory = new XmlBeanFactory(resource); XmlBeanFactory可以加载xml的配置文件。假设我们有一个Car类： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class Car &#123; private String brand; private String color; private int maxSpeed; public String getBrand() &#123; return brand; &#125; public void setBrand(String brand) &#123; this.brand = brand; &#125; public String getColor() &#123; return color; &#125; public void setColor(String color) &#123; this.color = color; &#125; public int getMaxSpeed() &#123; return maxSpeed; &#125; public void setMaxSpeed(int maxSpeed) &#123; this.maxSpeed = maxSpeed; &#125; public String toString()&#123; return &quot;the car is:&quot;+ getBrand() + &quot;, color is:&quot; +getColor() +&quot;, maxspeed is:&quot;+getMaxSpeed(); &#125; public Car() &#123; &#125; public Car(String brand, String color, int maxSpeed) &#123; this.brand = brand; this.color = color; this.maxSpeed = maxSpeed; &#125; public void introduce() &#123; System.out.println(&quot;brand:&quot; + brand + &quot;;color:&quot; + color + &quot;;maxSpeed:&quot; + maxSpeed); &#125;&#125; 我们通过在applicationContext.xml中配置： 1234&lt;bean id&#x3D;&quot;car1&quot; class&#x3D;&quot;spring.ioc.demo1.Car&quot; p:brand&#x3D;&quot;spring注入-红旗001&quot; p:color&#x3D;&quot;spring注入-紫色&quot; p:maxSpeed&#x3D;&quot;520&quot; &#x2F;&gt; 通过XmlBeanFactory实现启动Spring IoC容器： 12345678910public static void main(String[] args) &#123; ResourcePatternResolver resolver = new PathMatchingResourcePatternResolver(); Resource res = resolver.getResource(&quot;classpath:applicationContext.xml&quot;); BeanFactory factory = new XmlBeanFactory(res); //ApplicationContext factory=new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); Car car = factory.getBean(&quot;car1&quot;,Car.class); System.out.println(&quot;car对象已经初始化完成&quot;); System.out.println(car.getMaxSpeed());&#125; XmlBeanFactory通过Resource装载Spring配置信息冰启动IoC容器，然后就可以通过factory.getBean从IoC容器中获取Bean了。 通过BeanFactory启动IoC容器时，并不会初始化配置文件中定义的Bean，初始化动作发生在第一个调用时。 对于单实例（singleton）的Bean来说，BeanFactory会缓存Bean实例，所以第二次使用getBean时直接从IoC容器缓存中获取Bean。 ApplicationContext（实例化、配置、组装Bean）如果说BeanFactory是Spring的心脏，那么ApplicationContext就是完整的躯体了，ApplicationContext由BeanFactory派生而来，提供了更多面向实际应用的功能。在BeanFactory中，很多功能需要以编程的方式实现，而在ApplicationContext中则可以通过配置实现。 BeanFactorty接口提供了配置框架及基本功能，但是无法支持spring的aop功能和web应用。而ApplicationContext接口作为BeanFactory的派生，因而提供BeanFactory所有的功能。而且ApplicationContext还在功能上做了扩展，相较于BeanFactorty，ApplicationContext还提供了以下的功能： （1）MessageSource, 提供国际化的消息访问（2）资源访问，如URL和文件（3）事件传播特性，即支持aop特性（4）载入多个（有继承关系）上下文 ，使得每一个上下文都专注于一个特定的层次，比如应用的web层 ApplicationContext：是IOC容器另一个重要接口， 它继承了BeanFactory的基本功能， 同时也继承了容器的高级功能，如：MessageSource（国际化资源接口）、ResourceLoader（资源加载接口）、ApplicationEventPublisher（应用事件发布接口）等。 二者区别1.BeanFactroy采用的是延迟加载形式来注入Bean的，即只有在使用到某个Bean时(调用getBean())，才对该Bean进行加载实例化，这样，我们就不能发现一些存在的Spring的配置问题。而ApplicationContext则相反，它是在容器启动时，一次性创建了所有的Bean。这样，在容器启动时，我们就可以发现Spring中存在的配置错误。 相对于基本的BeanFactory，ApplicationContext 唯一的不足是占用内存空间。当应用程序配置Bean较多时，程序启动较慢。 BeanFacotry延迟加载,如果Bean的某一个属性没有注入，BeanFacotry加载后，直至第一次使用调用getBean方法才会抛出异常；而ApplicationContext则在初始化自身是检验，这样有利于检查所依赖属性是否注入；所以通常情况下我们选择使用 ApplicationContext。应用上下文则会在上下文启动后预载入所有的单实例Bean。通过预载入单实例bean ,确保当你需要的时候，你就不用等待，因为它们已经创建好了。 2.BeanFactory和ApplicationContext都支持BeanPostProcessor、BeanFactoryPostProcessor的使用，但两者之间的区别是：BeanFactory需要手动注册，而ApplicationContext则是自动注册。（Applicationcontext比 beanFactory 加入了一些更好使用的功能。而且 beanFactory 的许多功能需要通过编程实现而 Applicationcontext 可以通过配置实现。比如后处理 bean ， Applicationcontext 直接配置在配置文件即可而 beanFactory 这要在代码中显示的写出来才可以被容器识别。 ） 3.beanFactory主要是面对与 spring 框架的基础设施，面对 spring 自己。而 Applicationcontex 主要面对与 spring 使用的开发者。基本都会使用 Applicationcontex 并非 beanFactory 。 总结作用： BeanFactory负责读取bean配置文档，管理bean的加载，实例化，维护bean之间的依赖关系，负责bean的声明周期。 ApplicationContext除了提供上述BeanFactory所能提供的功能之外，还提供了更完整的框架功能：a. 国际化支持b. 资源访问：Resource rs = ctx. getResource(“classpath:config.properties”), “file:c:/config.properties”c. 事件传递：通过实现ApplicationContextAware接口 常用的获取ApplicationContext FileSystemXmlApplicationContext：从文件系统或者url指定的xml配置文件创建，参数为配置文件名或文件名数组，有相对路径与绝对路径。 12ApplicationContext factory&#x3D;new FileSystemXmlApplicationContext(&quot;src&#x2F;applicationContext.xml&quot;);ApplicationContext factory&#x3D;new FileSystemXmlApplicationContext(&quot;E:&#x2F;Workspaces&#x2F;MyEclipse 8.5&#x2F;Hello&#x2F;src&#x2F;applicationContext.xml&quot;); ClassPathXmlApplicationContext：从classpath的xml配置文件创建，可以从jar包中读取配置文件。ClassPathXmlApplicationContext 编译路径总有三种方式： 123ApplicationContext factory &#x3D; new ClassPathXmlApplicationContext(&quot;classpath:applicationContext.xml&quot;);ApplicationContext factory &#x3D; new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); ApplicationContext factory &#x3D; new ClassPathXmlApplicationContext(&quot;file:E:&#x2F;Workspaces&#x2F;MyEclipse8.5&#x2F;Hello&#x2F;src&#x2F;applicationContext.xml&quot;); XmlWebApplicationContext：从web应用的根目录读取配置文件，需要先在web.xml中配置，可以配置监听器或者servlet来实现 123&lt;listener&gt;&lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;&#x2F;listener-class&gt;&lt;&#x2F;listener&gt; 或 12345&lt;servlet&gt;&lt;servlet-name&gt;context&lt;&#x2F;servlet-name&gt;&lt;servlet-class&gt;org.springframework.web.context.ContextLoaderServlet&lt;&#x2F;servlet-class&gt;&lt;load-on-startup&gt;1&lt;&#x2F;load-on-startup&gt;&lt;&#x2F;servlet&gt; 这两种方式都默认配置文件为web-inf/applicationContext.xml，也可使用context-param指定配置文件 1234&lt;context-param&gt;&lt;param-name&gt;contextConfigLocation&lt;&#x2F;param-name&gt;&lt;param-value&gt;&#x2F;WEB-INF&#x2F;myApplicationContext.xml&lt;&#x2F;param-value&gt;&lt;&#x2F;context-param&gt; 依赖注入 IoC is also known as dependency injection (DI).org.springframework.beans、org.springframework.context是IOC容器的基础包 BeanFactory接口提供了一种高级的配置机制，能够管理任何类型的对象。 面向切面 AOP","categories":[],"tags":[]},{"title":"How to work by tomcat","slug":"How-to-work-by-tomcat","date":"2021-05-25T16:17:02.000Z","updated":"2021-06-19T09:43:50.065Z","comments":true,"path":"2021/05/26/How-to-work-by-tomcat/","link":"","permalink":"http://www.postman.life/2021/05/26/How-to-work-by-tomcat/","excerpt":"","text":"分析Tomcat源码的第一步首先让我们弄懂Tomcat架构体系![](How-to-work-by-tomcat/Tomcat architecture.jpg) The Server：Tomcat它自身，属于Web Server的一个实例(instance)。属于最上层的组件。可以通过端口打开/关闭，可以切换成Debug模式。在JVM中，只能创建一个Server Instance。通过端口的设置用以达到在一台机子运行不同端口的Server，每台Server相互独立，有自己的应用配置，应用之间不会造成相互的影响。 Service：Service是Engine容器的上层组件，封装了多个接受请求的Connector（连接器）和一个Engine容器。在Catalina（**Servlet** ）容器里中，它通过Http处理Servlet的请求并决定将请求传递到虚拟主机还是上下文(Context)。 每个Service代表一组Connector和一个Container（容器），用以管理客户端和服务器之间的连接。这些容器接受连接器的请求并处理这些请求。容器包含Web应用程序。 它负责接受请求，将请求路由到指定的Web应用程序和特定资源，并返回请求处理的结果。 连接器位于发出请求的客户端和容器之间，可以提供一些服务，例如SSL支持。 Connectors ：连接器可以链接应用程序与客户端，处理请求和返回对象。默认的端口是8080，如果不指定默认端口则为80。 Engines：虚拟主机引擎，一个Tomcat Server只有一个引擎。引擎将连接器的所有请求交给相应的（Host）虚拟主机去处理。在多宿主机器中。 引擎可能包含代表一组Web应用程序的主机和代表单个Web应用程序的上下文。 Host - 虚拟主机，通过其IP地址或主机名来区分 Contexts - Web Application Realms：管理引擎的User Authentication And Authorization(用户身份验证和授权), 通过应用配置，允许管理员对一个资源或一组资源设置权限。Valves：A Valve element represents a component that will be inserted into the request processing pipeline for the associated Catalina container (Engine, Host, or Context). Individual Valves have distinct processing capabilities 每个层级的容器（Engine, Host、Context, Wrapper ）均有对应的基础Valve实现，同时维护了一个Pipeline实例，我们可以在任何层级的容器 上针对请求处理进行扩展https://zhuanlan.zhihu.com/p/127824362 Access Log org.apache.catalina.valves.AccessLogValve 它创建日志文件以跟踪客户端访问信息。 Remote Address Filter org.apache.catalina.filters.RemoteAddrFilter 允许将提交请求的客户机的IP地址与一个或多个正则表达式进行比较，并允许该请求继续或拒绝处理来自此客户机的请求。 Remote Host Filter org.apache.catalina.filters.RemoteHostFilter 允许将提交此请求的客户机的主机名与一个或多个正则表达式进行比较，并允许请求继续或拒绝处理来自此客户机的请求 Request Dumper org.apache.catalina.filters.RequestDumperFilter 记录来自请求和响应对象的信息 更多详细的可以在官方文档找到 &lt;http://tomcat.apache.org/tomcat-9.0-doc/config/filter.html Loggers：在Tomcat中，使用的是Apcache Common的Juli日志框架。以确保Tomcat的内部日志和Web Application的日志隔离开来。 JVM中的类加载机制 Java通过类加载器动态的将Class加载到虚拟机中，而默认的类加载机制是通过双亲委派的方式来实现。 Class并不会一次性全都加载到内存里面，只是当被用到了才会被加载。 加载过程： 加载-&gt;链接-&gt;初始化 (Loading, Linking, and Initializing)。 通过加载类或者接口的二进制文件，链接并组合类和接口到虚拟机以便执行。初始化是执行类和接口的的初始化方法 我们可以使用这个命令，来查看一大堆被加载器加载的类 -verbose:class 由上图我们知道，JVM内置了三个类加载器 Boostrap ClassLoader （jre\\lib\\rt.jar or specify parameters） -Xbootclasspath 参数指定 Extension ClassLoader (jre\\lib\\ext*.jar or specify parameters) java.ext.dirs 系统变量所指定的路径下的jar Application ClassLoader (classpath) 类分别被不同的加载器加载，通过 getClassLoader()我们可以知道加载类的加载器是哪一个。 通过自底向上查看类是否被加载过，类加载器在通过名称加载类，如果父类加载器找不到，就会从子类加载器开始找，一直找不到就会抛出一个NoClassDefFoundError或ClassNotFoundException。 让我们再看Tomcat的类加载器 1234567 Bootstrap | System | Common &#x2F; \\Webapp1 Webapp2 ... Bootstrap该类加载器包含Java虚拟机提供的基本运行时类，以及系统扩展目录（$ JAVA_HOME / jre / lib / ext）中存在的JAR文件中的所有类。 注意：某些JVM可能将其实现为多个类加载器，或者可能根本不可见（作为类加载器） System这个类装入器通常是从类路径环境变量的内容初始化的。所有这些类对Tomcat内部类和web应用程序都是可见的。但是，标准的Tomcat启动脚本($CATALINA_HOME/bin/catalina.sh或%CATALINA_HOME%\\bin\\catalina.bat)完全忽略了类路径环境变量本身的内容，而是从以下库构建系统类加载器: $CATALINA_HOME/bin/bootstrap.jar -包含用于初始化Tomcat服务器的main()方法，以及它所依赖的类加载器实现类 $ CATALINA_BASE / bin / tomcat-juli.jar或$ CATALINA_HOME / bin / tomcat-juli.jar —记录实现类。 其中包括对java.util.logging API的增强类，称为Tomcat JULI $ CATALINA_HOME / bin / commons-daemon.jar — Apache Commons Daemon项目中的类。 这 Common该类加载器包含让Tomcat内部类和所有Web应用程序都可用的类 通常，不应将应用程序类放在这里。 此类加载器搜索的位置由$ CATALINA_BASE / conf / catalina.properties中的common.loader属性定义。 默认设置将按列出的顺序搜索以下位置： $ CATALINA_BASE / lib中解压缩的类和资源 $ CATALINA_BASE / lib中的JAR文件 $ CATALINA_HOME / lib中解压缩的类和资源 $ CATALINA_HOME / lib中的JAR文件 默认情况，会加载tomcat/bin的所有jar包。 WebappX 为在单个Tomcat实例中部署的每个Web应用程序创建的一个类加载器。 Web应用程序的/ WEB-INF / classes目录中的所有解压缩的类和资源，以及Web应用程序的/ WEB-INF / lib目录下的JAR文件中的类和资源，这些类和资源对应用程序是可访问的，但是外部是不能访问的。 也就是说不同的Web应用程序是不能互相访问的 除了上述加载器，Tomcat还有两个自定义加载器 12Catalina 负责加载Tomcat内部的类Shared 负责加载Tomcat下所有Web应用程序复用类 回到Bootstrap.init()方法 使用Catalina加载器初始化Catalina类 这边是加载命令行的命令 重要的是在启动时候的load()方法 通过保存一个Object的引用，再用反射去调用了Catalina.load()，实现了代码的解耦。Servier.xml的加载与解析 server.xml是放置Tomcat一些参数的地方。当找不到会去加载server-embed.xml 在加载完TomcatBaseConfig之后，也会加载一个组件[Digester]Digester是解析server.xml参数的地方。 在Java中，解析XML的方式有两种：一种是将文件读取到内存中，构造一个DOM树（对象模型集合），也就是我们俗称的DOM解析，最常用的就是DOM4J。另外一种SAX解析，一行一行的读取XML文件，通过监听获取节点。在读取完毕后释放内存，只会在某一时刻存在一行的内存数据。 有兴趣可以参考这篇文章 https://www.cnblogs.com/jiaan-geng/p/4866009.html Digester主要是对SAX的封装和抽象让我们看下面这一组参数： 123&lt;Server port=&quot;8005&quot; shutdown=&quot;SHUTDOWN&quot;&gt; &lt;Listener className=&quot;org.apache.catalina.startup.VersionLoggerListener&quot; /&gt;&lt;/&gt; Catalina.createStartDigester()中 123456&#x2F;&#x2F; Configure the actions we will be usingdigester.addObjectCreate(&quot;Server&quot;, &quot;org.apache.catalina.core.StandardServer&quot;, &quot;className&quot;);digester.addSetProperties(&quot;Server&quot;);digester.addSetNext(&quot;Server&quot;, &quot;setServer&quot;,&quot;org.apache.catalina.Server&quot;); 获取Server前缀的一组参数，读取到StandardServer类中，其中有一个私有变量port,默认值是8005，还有一个私有变量address，初始化值是”localhost”,这也就是为什么tomcat默认的host是本机了。 初始化生命周期组件 LifeCycle最上层的接口定义，以及生命周期的常量 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165public interface Lifecycle &#123; // ----------------------------------------------------- Manifest Constants /** * The LifecycleEvent type for the &quot;component before init&quot; event. */ public static final String BEFORE_INIT_EVENT = &quot;before_init&quot;; /** * The LifecycleEvent type for the &quot;component after init&quot; event. */ public static final String AFTER_INIT_EVENT = &quot;after_init&quot;; /** * The LifecycleEvent type for the &quot;component start&quot; event. */ public static final String START_EVENT = &quot;start&quot;; /** * The LifecycleEvent type for the &quot;component before start&quot; event. */ public static final String BEFORE_START_EVENT = &quot;before_start&quot;; /** * The LifecycleEvent type for the &quot;component after start&quot; event. */ public static final String AFTER_START_EVENT = &quot;after_start&quot;; /** * The LifecycleEvent type for the &quot;component stop&quot; event. */ public static final String STOP_EVENT = &quot;stop&quot;; /** * The LifecycleEvent type for the &quot;component before stop&quot; event. */ public static final String BEFORE_STOP_EVENT = &quot;before_stop&quot;; /** * The LifecycleEvent type for the &quot;component after stop&quot; event. */ public static final String AFTER_STOP_EVENT = &quot;after_stop&quot;; /** * The LifecycleEvent type for the &quot;component after destroy&quot; event. */ public static final String AFTER_DESTROY_EVENT = &quot;after_destroy&quot;; /** * The LifecycleEvent type for the &quot;component before destroy&quot; event. */ public static final String BEFORE_DESTROY_EVENT = &quot;before_destroy&quot;; /** * The LifecycleEvent type for the &quot;periodic&quot; event. */ public static final String PERIODIC_EVENT = &quot;periodic&quot;; /** * The LifecycleEvent type for the &quot;configure_start&quot; event. Used by those * components that use a separate component to perform configuration and * need to signal when configuration should be performed - usually after * &#123;@link #BEFORE_START_EVENT&#125; and before &#123;@link #START_EVENT&#125;. */ public static final String CONFIGURE_START_EVENT = &quot;configure_start&quot;; /** * The LifecycleEvent type for the &quot;configure_stop&quot; event. Used by those * components that use a separate component to perform configuration and * need to signal when de-configuration should be performed - usually after * &#123;@link #STOP_EVENT&#125; and before &#123;@link #AFTER_STOP_EVENT&#125;. */ public static final String CONFIGURE_STOP_EVENT = &quot;configure_stop&quot;; // --------------------------------------------------------- Public Methods /** * 添加监听器 * * @param listener The listener to add */ public void addLifecycleListener(LifecycleListener listener); /** * 获取所有的监听器 * * @return An array containing the life cycle listeners associated with this * life cycle. If this component has no listeners registered, a * zero-length array is returned. */ public LifecycleListener[] findLifecycleListeners(); /** * 移除当前的监听器 * * @param listener The listener to remove */ public void removeLifecycleListener(LifecycleListener listener); /** * 初始化方法，在INIT_EVENT成功之后执行 * * @exception LifecycleException if this component detects a fatal error * that prevents this component from being used */ public void init() throws LifecycleException; /** * 启动方法，在调用public之外的方法之前。执行顺序BEFORE_START_EVENT、START_EVENT、 * AFTER_START_EVENT */ public void start() throws LifecycleException; /** * 在STOP_EVENT时触发，优雅的关闭。 */ public void stop() throws LifecycleException; /** * 在完成DESTROY_EVENT状态时，调用销毁方法 */ public void destroy() throws LifecycleException; /** * 获取当前组件的生命周期状态 */ public LifecycleState getState(); /** * 获取String类型的生命周期状态 */ public String getStateName(); /** * Marker interface used to indicate that the instance should only be used * once. Calling &#123;@link #stop()&#125; on an instance that supports this interface * will automatically call &#123;@link #destroy()&#125; after &#123;@link #stop()&#125; * completes. */ public interface SingleUse &#123; &#125;&#125; 组件的生命周期1234567891011121314151617181920212223242526272829303132333435363738394041424344public enum LifecycleState &#123; NEW(false, null), //新状态 INITIALIZING(false, Lifecycle.BEFORE_INIT_EVENT), //正在初始化 INITIALIZED(false, Lifecycle.AFTER_INIT_EVENT), //初始化完毕 STARTING_PREP(false, Lifecycle.BEFORE_START_EVENT), //开始启动 STARTING(true, Lifecycle.START_EVENT), //启动中 STARTED(true, Lifecycle.AFTER_START_EVENT), //启动完毕 STOPPING_PREP(true, Lifecycle.BEFORE_STOP_EVENT), //准备停止 STOPPING(false, Lifecycle.STOP_EVENT), //停止中 STOPPED(false, Lifecycle.AFTER_STOP_EVENT), //已停止 DESTROYING(false, Lifecycle.BEFORE_DESTROY_EVENT), //正在释放or正在销毁 DESTROYED(false, Lifecycle.AFTER_DESTROY_EVENT), //已消亡 FAILED(false, null); //失败 private final boolean available; private final String lifecycleEvent; private LifecycleState(boolean available, String lifecycleEvent) &#123; this.available = available; this.lifecycleEvent = lifecycleEvent; &#125; /** * May the public methods other than property getters/setters and lifecycle * methods be called for a component in this state? It returns * &lt;code&gt;true&lt;/code&gt; for any component in any of the following states: * &lt;ul&gt; * &lt;li&gt;&#123;@link #STARTING&#125;&lt;/li&gt; * &lt;li&gt;&#123;@link #STARTED&#125;&lt;/li&gt; * &lt;li&gt;&#123;@link #STOPPING_PREP&#125;&lt;/li&gt; * &lt;/ul&gt; * * @return &lt;code&gt;true&lt;/code&gt; if the component is available for use, * otherwise &lt;code&gt;false&lt;/code&gt; */ public boolean isAvailable() &#123; return available; &#125; public String getLifecycleEvent() &#123; return lifecycleEvent; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960/** * General event for notifying listeners of significant changes on a component * that implements the Lifecycle interface. * * @author Craig R. McClanahan */public final class LifecycleEvent extends EventObject &#123; private static final long serialVersionUID = 1L; /** * Construct a new LifecycleEvent with the specified parameters. * * @param lifecycle Component on which this event occurred * @param type Event type (required) * @param data Event data (if any) */ public LifecycleEvent(Lifecycle lifecycle, String type, Object data) &#123; super(lifecycle); this.type = type; this.data = data; &#125; /** * The event data associated with this event. */ private final Object data; /** * The event type this instance represents. */ private final String type; /** * @return the event data of this event. */ public Object getData() &#123; return data; &#125; /** * @return the Lifecycle on which this event occurred. */ public Lifecycle getLifecycle() &#123; return (Lifecycle) getSource(); &#125; /** * @return the event type of this event. */ public String getType() &#123; return this.type; &#125;&#125; LifecycleBase1public abstract class LifecycleBase implements Lifecycle &#123;&#125; Base implementation of the Lifecycle interface that implements thestate transition rules for start() and stop()生命周期接口的基本实现，它实现了start()和stop()的状态转换规则 Tomcat中的组件都需要实现Lifecycle接口，作用于对组件的启动、初始化、关闭的标准流程化 1234567891011121314@Overridepublic final synchronized void init() throws LifecycleException &#123; if (!state.equals(LifecycleState.NEW)) &#123; invalidTransition(Lifecycle.BEFORE_INIT_EVENT); &#125; try &#123; setStateInternal(LifecycleState.INITIALIZING, null, false); initInternal(); &#x2F;&#x2F;各个子类实现protected该方法初始化组件 setStateInternal(LifecycleState.INITIALIZED, null, false); &#125; catch (Throwable t) &#123; handleSubClassException(t, &quot;lifecycleBase.initFail&quot;, toString()); &#125;&#125; 实现了该接口的组件，当状态改变时会触发该事件监听器 123456789101112public interface LifecycleListener &#123; &#x2F;** * Acknowledge the occurrence of the specified event. * * @param event LifecycleEvent that has occurred *&#x2F; public void lifecycleEvent(LifecycleEvent event);&#125; Tomcat各个组件都是先分别执行init()方法，初始化完毕之后才依次执行start()方法 关于JNDI https://docs.oracle.com/javase/tutorial/jndi/overview/index.html ContextConfig负责加载上下文配置，比如 web.xml 由webConfig()加载 在Tomcat中 第一个初始化的组件是Global JNDI resources 123456789&#x2F;** * Helper class used to initialize and populate the JNDI context associated * with each context and server. * * @author Remy Maucherat *&#x2F;public class NamingContextListener implements LifecycleListener, ContainerListener, PropertyChangeListener &#123;&#125; 源码注释中写道，这是一个用来初始化和填充每个上下文和服务器关联的JNDI上下文 1 Tomcat Request对象的生成一个Request的请求大概会经过以下步骤 线程-&gt;Socket-&gt;Protocol-&gt;HTTP11&gt;CoyoteAdapter-&gt;StandardEngineValue管道-&gt;AccessLogValue管道 -&gt; ErrorReportValue-&gt;StandardHostValue-&gt;AuthenticatorBase-&gt;StandardContextValue-&gt;StandardWrapperValue-&gt;ApplicationFilterChain-&gt;ErrorPageFilter-&gt;最终到达HttpServlet 连接器与容器的桥梁——CoyoteAdapter未完………..","categories":[],"tags":[]},{"title":"MySQL性能管理及架构设计","slug":"MySQL/MySQL性能管理及架构设计","date":"2020-11-22T08:28:38.000Z","updated":"2021-06-14T13:59:33.945Z","comments":true,"path":"2020/11/22/MySQL/MySQL性能管理及架构设计/","link":"","permalink":"http://www.postman.life/2020/11/22/MySQL/MySQL%E6%80%A7%E8%83%BD%E7%AE%A1%E7%90%86%E5%8F%8A%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/","excerpt":"","text":"[TOC] 什么情况会影响数据库性能大量的并发和超高的CPU使用率 磁盘IO 网卡流量 大表 记录行数巨大，单表超过千万行 表数据文件巨大，表数据文件超过10G 大表对DDL操作的影响(风险) 建立索引需要很长的时间 MySQL版本&lt;5.5建立索引会锁表 MySQL版本&gt;= 5.5虽然不会锁表但会引起主从延迟 修改表结构需要长时间锁表 会造成长时间的主从延迟 影响正常的数据操作 如何处理数据库中的大表 分库分表把一张大表分成多个小表 难点： 分表主键的选择 分表后跨分区数据的查询和统计 大表的历史数据归档 - 减少对前后端业务的影响 难点： 归档时间点的选择 如何进行归档操作 什么是大事务 - 大事务带来的问题定义∶ ​ 运行时间比较长，操作的数据比较多的事务 风险: ​ 锁定太多的数据，造成大量的阻塞和锁超时 ​ 回滚时所需要时间比较长 ​ 执行时间长，容易造成主从延迟 如何处理大事务 避免一次处理太多的数据 移除不必要在事务中的SELECT操作 什么影响了MySQL性能 服务器硬件（CPU、内存等） 服务器系统 数据库存储引擎的选择 数据库参数配置 数据库结构设计和SQL语句(表结构设计、SQL语句的编写和优化) CPU资源和可用内存大小如何选择CPU？ 我们的应用是CPU密集型的吗？ 我们系统的并发量如何？ 衡量数据库处理能力的指标：QPS（每秒处理SQL的数量） WEB类应用：核心数量比频率重要 使用正确的服务器版本（64位操作系统使用64位服务器版本） 内存越多越好，但对性能影响有限。无限增加内存不是银弹 缓存可以把多个写入加载到内存然后一次写入到磁盘 磁盘的配置和选择使用传统机器硬盘： 存储容量 传输速度 访问时间 主轴转速 物理尺寸 多个容量较小的磁盘组成一组容量更大的磁盘 使用RAID（磁盘冗余队列）增强传统机器硬盘的性能： 使用固态存储SSD和PCIe卡： 更好的随机读写性能 更好的支持并发 使用场景： 存在于大量随机I/O的场景 使用于结局单线程负载的I/O瓶颈 使用网络存储NAS和SAN： 网络存储使用的场景 数据库备份 操作系统对性能的影响适合的操作系统 Window FreeBSD Solaris Linux Centos系统参数优化内核相关参数（/etc/sysctl.conf） 网络层： net.core.somaxconn=65535 net.core.netdev_max_backlog=65535 net.ipv4.tcp_max_syn_backlog=65535 net.ipv4.tcp_fin_timeout = 10 net.ipv4.tcp_tw_reuse = 1 net.ipv4.tcp_tw_recycle = 1 net.core.wmem_default =87380 net.core.wmem_max =16777216 net.core.rmem_default =87380 net.core.rmem_max =16777216 net.ipv4.tcp_keepalive_time = 120 net.ipv4.tcp_keepalive_intvl = 30 net.ipv4.tcp_keepalive_probes = 3 ​ 内存： kernel.shmmax = 4294967295 - 单个共享内存段的最大值 这个参数应该设置的足够大，以便能在一个共享内存段下容纳下整个的Innodb缓冲池的大小。 vm.swappiness = o这个参数当内存不足时会对性能产生比较明显的影响 增加资源限制(/etc/security/limit.conf) soft nofile 65535 hard nofile 65535 磁盘调度策略(/sys/block/devname/queue/scheduler) cat /sys/block/sda/queue/scheduler noop anticipatory deadline [cfq] noop（电梯式调度策略 - FIFO 队列） deadline（截止时间调度策略） anticipatory(预料I/O调度策略) 文件系统对性能的影响Window FAT NTFS Linux EXT3 EXT4 XFS EXT3/4系统的挂载参数(/etc/fstab) data=writeback | ordered l journals noatime , nodiratime /dev/sda1/ext4 noatime,nodiratime,data=writeback 1 1 MySQL体系结构 MyISAM存储引擎在MySQL 5.1及之前的版本，MyISAM是默认的存储引擎 特性 加锁与并发MyISAM对整张表加锁，而不是针对行。读取时会对需要读到的所有表加共享锁，写入时则对表加排他锁。但是在表有读取查询的同时，也可以往表中插入新的记录(这被称为并发插入，CONCURRENT INSERT)。 表损坏和修复MyISAM 存储引擎的某个表文件出错之后，仅影响到该表，而不会影响到其他表，更不会影响到其他的数据库。如果我们正在运行过程中发现某个 MyISAM 表出现问题了， 则可以在线通过 check table 命令来尝试校验他，并可以通过 repair table 命令来尝试修 复。在数据库关闭状态下，我们也可以通过 myisamchk 工具来对数据库中某个（或某些）表进行检测或者修复。不过强烈建议不到万不得已不要轻易对表进行修复操作，修复之前尽量 做好可能的备份工作，以免带来不必要的后果。 索引特性即使是BLOB和TEXT等长字段，也可以基于其前500个字符创建索引。MyISAM也支持全文索引。可以指定DELAY_KEY_WRITER来延迟更新索引键 优缺点： 不支持事务和行级锁 崩溃后无法安全恢复 存储MyISAM 存储引擎的表在数据库中，每一个表都被存放为三个以表名命名的物理文件。 定义 文件 表结构定义信息 .FRM 表的数据 .MYD 索引数据 .MYI 每个表都有且仅有这样三个文件做为 MyISAM 存储类型的表的存储，也就是说不管这个表有多少个索引，都是存放在同一个.MYI 文件中。 MyISAM压缩表默认是不压缩的，压缩方式： 创建表时通过 ROW_FORMAT 来指定 {COMPRESSED | DEFAULT}， myisampack 工具 而在非压缩的情况下，表是静态还是动态，就和我们表中个字段的定义相关了。只要表中有可变长度类型的字段存在，那么该表就肯定是DYNAMIC 格式的，如果没有任何可变长度的字段，则为 FIXED 格式。 适用场景： 非事务性应用 只读类应用 空间类应用 InnoDB存储引擎特性： 支持事务安装READ UNCOMMITTED， READ COMMITTED， REPEATABLE READ SERIALIZABLE 数据多版本读取在事务支持的同时，为了保证数据的一致性已经并发时候的性能，通过对 undo 信息，实现了数据的多版本读取 行级锁的支持改变了MyISAM的锁机制，通过索引实现了行锁，最大程度支持并发 实现外键虽然很多数据库系统调优专家都建议不要这样做，但是对于不少用户来说在数据 库端加如外键控制可能仍然是成本最低的选择 支持符号链接 Redo Log （持久性） 和Undo Log（回滚） 事务安全性主要就是通过Redo 日志和记录在表空间中的Undo 信息来保证的。 Redo 日志中记录了Innodb 所做的所有物理变更和事务信息， 通过Redo 日志和Undo 信息，Innodb 保证了在任何情况下的事务安全性。 Innodb 的redo日志同样默认存放在数据目录下， innodb_log_group_home_dir 更改设置日志的存放位置， innodb_log_files_in_group 设置日志的数量。 Innodb使用表空间进行数据存储 innodb_file_per_table ON:独立表空间:tablename. ibd OFF:系统表空间:ibdataX 定义 文件 表结构定义信息 .FRM 表的数据、索引数据 .IBD 系统表空间和独立表空间要如何选择 比较: 系统表空间无法简单的收缩文件大小 独立表空间可以通过optimize table命令收缩系统文件 系统表空间会产生IO瓶颈 独立表空间可以同时向多个文件刷新数据 MySQL服务器参数介绍MySQL获取配置信息路径 命令行参数mysqld_safe –datadir=/data/sql_data 配置文件 mysqld –help –verbose | grep -A 1 ‘Default optiorns /etc/my.cnf /etc/mysql/my.cnf /home/mysql/my.cnf ~/.my.cnf MySQL配置参数的做用域 全局参数 set global参数名=参数值; set @@global.参数名:=参数值; 会话参数 set [session]参数名=参数值; set @@session.参数名:=参数值; 内存配置相关参数 确定可以使用的内存的上限 确定MySQL的每个连接使用的内存 sort_buffer_size 每个线程排序缓冲区的大小 join_buffer_size 每个连接所使用连接缓冲区的大小 read_buffer_size MyISAM 查询缓冲区大小 （4k的倍数） read_rnd_buffer_size 索引缓冲区的大小 确定需要为操作系统保留多少内存 （生产环境一台服务器运行一个服务器实例） 如何为缓存池分配内存 *Innodb_buffer_pool_size 总内存 - (每个线程所需要的内存连接数) - 系统保留内存**， 缓存Innodb的索引、数据、哈希索引、锁、插入缓冲、其它数据结构、延迟写入 key_buffer_size MyISAM 缓冲池，缓存索引、数据则由操作系统缓存 12select sum(index_length)from information_schema.tables where engine&#x3D;&#39;myisam&#39; I/O相关配置参数（决定MySQL如何同步缓冲池的数据到磁盘上持久化）Innodb I/O相关配置InnoDb写入数据过程 事务日志缓冲区 -&gt; 操作系统cache -&gt; 刷新到磁盘日志 innodb_log_group_home_dir 更改设置日志的存放位置， innodb_log_files_in_group 设置日志的数量。 Innodb_log_buffer_size 事务日志总大小 = Innodb_log_files_in_group * Innodb_log_file_size Innodb_flush_log_at_trx_commit 0:每秒进行一次log写入cache，并flush log到磁盘 1[默认]:在每次事务提交执行log写入cache，并flush log到磁盘 2[建议]:每次事务提交,执行log数据写入到cache，每秒执行一次flush log到磁盘 Innodb_flush_method=O_DIRECT Innodb_file_per_table = 1 是否使用表空间 Innodb_doublewrite = 1 双写缓存 MyISAM I/O相关配置 delay_key_write OFF:每次写操作后刷新键缓冲中的脏块到磁盘 ON:只对在键表时指定了delay_key_write选项的表使用延迟刷新 ALL:对所有MYISAM表都使用延迟键写入 安全相关配置参数expire_logs_days 指定自动清理binlog的天数 max_allowed_packet 控制MySQL可以接收的包的大小 （如果主从一定设置一致） skip_name_resolve 禁用DNS查找 sysdate_is_now 确保sysdate()返回确定性日期 read_only 禁止非super权限的用户写权限 （建议在从库中启用，只接受从主库传过来的数据变更） skip_slave_start 禁用Slave自动恢复 sql_mode 设置MySQL所使用的SQL模式 strict_trans_tables no_engine_subtitution no_zero_date no_zero_in_date only_full_group_by 其它常用配置参数sync_binlog 控制MySQL如何向磁盘刷新binlog tmp_table_size、max_heap_table_size 控制内存临时表大小、建议保持一致 max_connections 控制允许的最大连接数（默认100、通常设置成2000或根据应用环境来定） 数据库结构设计对性能的影响（对性能影响比较大）什么影响了性能 过分的反范式化为表建立太多的列 过分的范式化造成太多的表关联 （MySQL限制最多可以关联61张表） 在OLTP环境中使用不恰当的分区表 （大表在物理上分成小表、实际上还是一张表、分区键选择比较关键） 使用外键保证数据的完整性 （在对使用外键的修改时，MySQL会对外键进行检查，会带来额外的锁开销） 总结性能优化顺序 数据库结构设计和SQL语句 数据库存储引擎的选择和参数配置 系统选择及优化 硬件升级 MySQL基准测试什么是基准测试定义 基准测试是一种测量和评估软件性能指标的活动用于建立某个时刻的性能基准，以便当系统发生软硬件变化时重新进行基准测试以评估变化对性能的影响 所以， 基准测试是针对系统设计的一种压力测试 基准测试的目的 建立MySQL服务器的性能基准线 模拟比当前系统更高的负载，以找出系统的扩展瓶颈 测试不同的硬件、软件和操作系统配置 证明新的硬件设备是否配置正确 基准测试的策略主要有两种主要的策略： 针对整个系统的整体测试（集成式） 优点：能够测试整个系统的性能，包括web服务器缓存、数据库等。 ​ 能反映出系统中各个组件接口间的性能问题体现真实性能状况。 缺点：测试设计复杂，消耗时间长。 单独测试MySQL（单组件） 优点：测试设计简单，所需消耗时间短。 缺点：无法全面了解整个系统的性能基线。 为什么要针对整个系统做集成式测试，而不是单独测试MySQL： 测试整个应用系统，包括Web服务器、应用代码、网络和数据库是非常有用的，因为用户关注的并不仅仅是MySQL本身的性能，而是应用整体的性能。 MySQL并非总是应用的瓶颈，通过整体的测试可以揭示这一点。只有对应用做整体测试，才能发现各部分之间的缓存带来的影响。 整体应用的集成式测试更能揭示应用的真实表现，而单独组件的测试很难做到这一点。 单独测试MySQL****： 需要比较不同的schema或查询的性能。 针对应用中某个具体问题的测试。 为了避免漫长的基准测试，可以通过一个短期的基准测试，做快速的“周期循环”，来检测出某些调整后的效果。 MySQL基准测试的常见指标 单位时间内所处理的事务数(TPS) 单位时间内所处理的查询数(QPS ) 响应时间 所需的整体时间，时间单位可能是微妙、毫秒、秒、或者分钟。根据不同的时间单位可以计算出平均响应时间、最小响应时间、最大响应时间和所占百分比。 并发性 同时工作的线程数或者连接数 可扩展性 简单地说，可扩展性指的是，给系统增加一倍的工作，在理想情况下就能获得两倍的结果（即吞吐量增加一倍)。或者说，给系统增加一倍的资源（比如两倍的CPU 数)，就可以获得两倍的吞吐量。 基准测试的步骤决定是采用标准的基准测试，还是设计专用的测试 准备基准测试及数据收集脚本 运行基准测试 保存及分析基准测试结果 信息收集脚本 - CPU使用率、IO、网络流量、状态与计数器信息等12345678910111213141516171819202122#!/bin/bashINTERVAL=5PREFIX=/home/imooc/benchmarks/$INTERVAL-sec-statusRUNFILE=/home/imooc/benchmarks/runningecho &quot;1&quot; &gt; $RUNFILEMYSQL=/usr/local/mysql/bin/mysql$MYSQL -e &quot;show global variables&quot; &gt;&gt; mysql-variableswhile test -e $RUNFILE; do file=$(date +%F_%I) sleep=$(date +%s.%N | awk &#x27;&#123;print 5 - ($1 % 5)&#125;&#x27;) sleep $sleep ts=&quot;$(date +&quot;TS %s.%N %F %T&quot;)&quot; loadavg=&quot;$(uptime)&quot; echo &quot;$ts $loadavg&quot; &gt;&gt; $PREFIX-$&#123;file&#125;-status $MYSQL -e &quot;show global status&quot; &gt;&gt; $PREFIX-$&#123;file&#125;-status &amp; echo &quot;$ts $loadavg&quot; &gt;&gt; $PREFIX-$&#123;file&#125;-innodbstatus $MYSQL -e &quot;show engine innodb status&quot; &gt;&gt; $PREFIX-$&#123;file&#125;-innodbstatus &amp; echo &quot;$ts $loadavg&quot; &gt;&gt; $PREFIX-$&#123;file&#125;-processlist $MYSQL -e &quot;show full processlist\\G&quot; &gt;&gt; $PREFIX-$&#123;file&#125;-processlist &amp; echo $tsdoneecho Exiting because $RUNFILE does not exists 分析脚本123456789101112131415161718#!/bin/bashawk &#x27; BEGIN &#123; printf &quot;#ts date time load QPS&quot;; fmt=&quot; %.2f&quot;; &#125; /^TS/ &#123; ts = substr($2,1,index($2,&quot;.&quot;)-1); load = NF -2; diff = ts - prev_ts; printf &quot;\\n%s %s %s %s&quot;,ts,$3,$4,substr($load,1,length($load)-1); prev_ts=ts; &#125; /Queries/&#123; printf fmt,($2-Queries)/diff; Queries=$2 &#125; &#x27; &quot;$@&quot; 基准测试方法避免以下常见的错误 使用真实数据的子集而不是全集。例如应用需要处理几百GB的数据，但测试只有1GB数据﹔或者只使用当前数据进行测试，却希望模拟未来业务大幅度增长后的情况。 使用错误的数据分布。例如使用均匀分布的数据测试，而系统的真实数据有很多热点区域（随机生成的测试数据通常无法模拟真实的数据分布)。 使用不真实的分布参数，例如假定所有用户的个人信息（profile）都会被平均地读取在多用户场景中，只做单用户的测试。在单服务器上测试分布式应用。 与真实用户行为不匹配。例如Web页面中的“思考时间”。真实用户在请求到一个页面后会阅读一段时间，而不是不停顿地一个接一个点击相关链接。 反复执行同一个查询。真实的查询是不尽相同的，这可能会导致缓存命中率降低。而反复执行同一个查询在某种程度上，会全部或者部分缓存结果。 没有检查错误。如果测试的结果无法得到合理的解释，比如一个本应该很慢的查询突然变快了，就应该检查是否有错误产生。否则可能只是测试了MySQL检测语法错误的速度了。基准测试完成后，一定要检查一下错误日志，这应当是基本的要求。 忽略了系统预热(warm up)的过程。例如系统重启后马上进行测试。有时候需要了解系统重启后需要多长时间才能达到正常的性能容量，要特别留意预热的时长。反过来说，如果要想分析正常的性能，需要注意，若基准测试在重启以后马上启动,则缓存是冷的、还没有数据，这时即使测试的压力相同，得到的结果也和缓存已经装满数据时是不同的。 使用默认的服务器配置。 测试时间太短。基准测试需要持续一定的时间。后面会继续讨论这个话题。 MySQL基准测试工具之mysqlslap常用参数说明–auto-generate-sql 由系统自动生成SQL脚本进行测试 –auto-generate-sql-add-autoincrement 在生成的表中增加自增ID –auto-generate-sql-load-type 指定测试中使用的查询类型 –auto-generate-sql-write-number 指定初始化数据时生成的数据量 –concurrency 指定并发线程的数量 –engine指定要测试表的存储引擎，可以用逗号分割多个存储引擎 –no-drop 指定不清理测试数据 –iterations 指定测试运行的次数 –number-of-queries 指定每一个线程执行的查询数量 –debug-info 指定输出额外的内存及CPU统计信息 –number-int-cols指定测试表中包含的INT类型列的数量 –number-char-cols 指定测试表中包含的varchar类型的数量 –create-schema 指定了用于执行测试的数据库的名字 –query 用于指定自定义SQL的脚本 –only-print 并不运行测试脚本，而是把生成的脚本打印出来 案例1mysqlslap -uroot -p --concurrency=1,50,100,200 --iterations=3 --number-int-cols=5 --number-char-cols=5 --auto-generate-sql --auto-generate-sql-add-autoincrement --engine=myisam,innodb --number-of-queries=10 --create-schema=sbtest 结果 Benchmark Running for engine myisam Average number of seconds to run all queries: 0.015 seconds Minimum number of seconds to run all queries: 0.015 seconds Maximum number of seconds to run all queries: 0.016 seconds Number of clients running queries: 1 Average number of queries per client: 10 Benchmark Running for engine myisam Average number of seconds to run all queries: 0.557 seconds Minimum number of seconds to run all queries: 0.235 seconds Maximum number of seconds to run all queries: 1.203 seconds Number of clients running queries: 50 Average number of queries per client: 0 Benchmark Running for engine myisam Average number of seconds to run all queries: 0.437 seconds Minimum number of seconds to run all queries: 0.437 seconds Maximum number of seconds to run all queries: 0.438 seconds Number of clients running queries: 100 Average number of queries per client: 0 Benchmark Running for engine myisam Average number of seconds to run all queries: 0.875 seconds Minimum number of seconds to run all queries: 0.859 seconds Maximum number of seconds to run all queries: 0.891 seconds Number of clients running queries: 200 Average number of queries per client: 0 Benchmark Running for engine innodb Average number of seconds to run all queries: 0.016 seconds Minimum number of seconds to run all queries: 0.016 seconds Maximum number of seconds to run all queries: 0.016 seconds Number of clients running queries: 1 Average number of queries per client: 10 Benchmark Running for engine innodb Average number of seconds to run all queries: 0.104 seconds Minimum number of seconds to run all queries: 0.093 seconds Maximum number of seconds to run all queries: 0.110 seconds Number of clients running queries: 50 Average number of queries per client: 0 Benchmark Running for engine innodb Average number of seconds to run all queries: 0.198 seconds Minimum number of seconds to run all queries: 0.188 seconds Maximum number of seconds to run all queries: 0.203 seconds Number of clients running queries: 100 Average number of queries per client: 0 Benchmark Running for engine innodb Average number of seconds to run all queries: 1.036 seconds Minimum number of seconds to run all queries: 0.375 seconds Maximum number of seconds to run all queries: 1.375 seconds Number of clients running queries: 200 Average number of queries per client: 0 MySQL基准测试工作之 sysbench常用参数 –test 用于指定所要执行的测试类型，支持以下参数 Fileio文件系统I/O性能测试 cpu cpu性能测试 memory 内存性能测试 Oltp 测试要指定具体的lua脚本 –myql-db 用于指定执行基准测试的数据库名 –mysql-table-engine 用于指定所使用的存储引擎 –oltp-tables-count 执行测试的表的数量 –oltp-table-size 指定每个表中的数据行数 –num-threads 指定测试的并发线程数量 –max-time 指定最大的测试时间 –report-interval 指定间隔多长时间输出一次统计信息 –mysql-user 指定执行测试的MySQL用户 –mysql-password 指定执行测试的MySQL用户的密码 prepare 用于准备测试数据 run 用于实际进行测试 cleanup 用于清理测试数据 数据库结构优化良好的数据库逻辑设计和物理设计是数据库获得高性能的基础 数据库结构优化的目的 减少数据冗余 尽量避免数据维护中出现更新，插入和删除异常 插入异常∶如果表中的某个实体随着另一个实体而存在 更新异常∶如果更改表中的某个实体的单独属性时，需要对多行进行更新 删除异常:如果删除表中的某一实体则会导致其他实体的消失 节约数据存储空间 提高查询效率 数据库结构设计的步骤需求分析： 全面了解产品设计的存储需求 存储需求 数据处理需求 数据的安全性和完整性 逻辑设计： 设计数据的逻辑存储结构 数据实体之间的逻辑关系，解决数据冗余和数据维护异常 物理设计：跟所使用的数据库特点进行表结构设计 关系型数据库: Oralce,SQLServer,MysqL,postgressQL 非关系型数据库:mongo,Redis,Hadoop 存储引擎：Innodb 维护优化根据实际情况对索引、存储结构等进行优化 数据库设计范式范式和反范式（数据的表示方法）从完全的范式化到完全的反范式化，以及两者的折中。 在范式化的数据库中，每个事实数据会出现并且只出现一次。相反，在反范式化的数据库中，信息是冗余的，可能会存储在多个地方。 从完全的范式化到完全的反范式化，以及两者的折中.在范式化的数据库中，每个事实数据会出现并且只出现一次.相反，在反范式化的数据库中，信息是冗余的，可能会存储在多个地方. 参考地址：https://www.jianshu.com/p/bd1f6a712d41 https://blog.csdn.net/u013585204/article/details/108854457 需求分析及逻辑设计 - 范式化用户登录及用户管理功能 用户必须注册并登陆系统才能进行网上交易 同一时间一个用户只能在一个地方登陆 用户信息∶{用户名,密码,手机号,姓名,注册日期,在线状态,出生日期} 只有一个业务主键,一定是符合第二范式 没有属性和业务主键存在传递依赖的关系,符合第三范式 商品展示及商品管理功能 需求分析及逻辑设计 - 反范式化 范式的优点和缺点 范式化的更新操作通常比反范式化要快。 当数据较好地范式化时,就只有很少或者没有重复数据，所以只需要修改更少的数据。（可以尽量的减少数据冗余） 范式化的表通常更小，可以更好地放在内存里，所以执行操作会更快。 很少有多余的数据意味着检索列表数据时更少需要DISTINCT或者GROUP BY语句。还是前面的例子:在非范式化的结构中必须使用DISTINCT或者GROUP BY才能获得一份唯一的部门列表，但是如果部门（DEPARTMENT)是一张单独的表，则只需要简单的查询这张表就行了。 范式化设计的schema的缺点是通常需要关联。稍微复杂一些的查询语句在符合范式的 schema上都可能需要至少一次关联，也许更多。这不但代价昂贵，也可能使一些索引策 略无效。例如，范式化可能将列存放在不同的表中，而这些列如果在一个表中本可以属于 同一个索引。 反范式的优点和缺点反范式化的schema因为所有数据都在一张表中，可以很好地避免关联。 如果不需要关联表，则对大部分查询最差的情况——即使表没有使用索引——是全表扫 描。当数据比内存大时这可能比关联要快得多，因为这样避免了随机I/O。 混用范式化和反范式化完全的范式化和完全的反范式schema都是实验室才有的东西 真实的世界中很少会这么极端地的使用，实际应用中经常需要混用。可能使用部分范式化的schema、缓存表、以及其他技巧。 缓存表和汇总表有时提升性能最好的方法是在同一张表中保存衍生的冗余数据。然而，有时也需要创建一 张完全独立的汇总表或缓存表（特别是为满足检索的需求时)。如果能容许少量的脏数 据，这是非常好的方法，但是有时确实没有选择的余地（例如，需要避免复杂、昂贵的实 时更新操作)。 缓存表用来表示存储那些可以比较简单地从schema其他表获取数据的表 汇总表则保存使用GROUP BY语句聚合数据的表 物理设计定义数据库、表及字段的命名规范 数据库、表及字段的命名要遵守可读性原则 数据库表及字段的命名要遵守表意性原则 数据库表及字段的命名要遵守长名原则 选择合适的存储引擎 为表中的字段选择合适的数据类型当一个列可以选择多种数据类型时， 应该优先考虑数字类型， 其次是日期或二进制类型， 最后是字符类型。 对于相同级别的数据类型，应该优先选择占用空间小的数据类型 如何选择正确的整数类型 如何选择正确的实数类型 如何选择VARCHARVARCHAR类型的存储特点 varchar用于存储变长字符串，只占用必要的存储空间列的 最大长度小于255则只占用一个额外字节用于记录字符串长度 列的最大长度大于255则要占用两个额外字节用于记录字符串长度 VARCHAR长度的选择问题 使用最小的符合需求的长度 varchar(5)和varchar(200)存储’MySQL’字符串性能不同 VARCHAR的适用场景 字符串列的最大长度比平均长度大很多字符串列很少被更新 使用了多字节字符集存储字符串 如何选择CHAR类型CHAR类型的存储特点 CHAR类型是定长的 字符串存储在CHAR类型的列中会删除末尾的空格 CHAR类型的最大宽度为255 CHAR类型的适用场景 CHAR类型适合存储所长度近似的值（MD5、身份证、手机号） CHAR类型适合存储短字符串 CHAR类型适合存储经常更新的字符串列 如何选择存储日期数据DATETIME类型​ 以YYYY-MM-DD HH:MM:SS[.fraction]格式存储日期时间 ​ datetime = YYYY-MM-DD HH:MM:SS ​ datetime(6) = YYYY-MM-DD HH:MM:SS.fraction ​ DATATIME类型与时区无关，占用8个字节的存储空间 ​ 时间范围1000-01-01 00:00:00到9999-12-31 23:59:59 TIMESTAMP类型​ 存储了由格林尼治时间1970年1月1日到当前时间的秒数 ​ 以YYYY-MM-DD HH:MM:SS.[.fraction]的格式显示,占用4个字节 ​ 时间范围1970-01-01到2038-01-19 ​ timestamp类型显示依赖于所指定的时区 ​ 在行的数据修改时可以自动修改timestamp列的值 DATE类型和time类型date类型的优点： ​ 占用的字节数比使用字符串、datetime、int存储要少，使用date类型只需要3个字节 ​ date类型用于保存1000-01-01到9999-12-31之间的日期 ​ time类型用于存储时间数据，格式为HH:MM:SS 存储日期时间数据的注意事项 不要使用字符串类型来存储日期时间数据 日期时间类型通常比字符串占用的存储空间小 日期时间类型在进行查找过滤时可以利用日期来进行对比 日期时间类型还有着丰富的处理函数，可以方便的对时期类型进行日期计算 使用Int存储日期时间不如使用Timestamp类型 物理设计总结 如何为Innodb选择主键 主键应该尽可能的小 主键应该是顺序增长的 Innodb的主键和业务主键可以不同 MySQL高可用架构设计MySQL复制功能复制解决了什么问题 实现在不同服务器上的数据分布利用二进制日志增量进行 不需要太多的带宽 但是使用基于行的复制在进行大批量的更改时会对带宽带来一定的压力 特别是跨IDC环境下进行复制应该分批进行 实现在不同服务器上的数据分布实现数据读取的负载均衡 需要其它组件配合完成 利用DNS轮询的方式把程序的读连接到不同的备份数据库使用LVS, haproxy这样的代理方式 非共享架构，同样的数据分布在多台服务器上 增强了数据安全性 利用备库的备份来减少主库负载 实现数据库高可用和故障切换 实现数据库在线升级 MySQL二进制日志 记录了所有对MySQL数据库的修改事件 包括增删改查事件和对表结构的修改事件 使用binlog命令行工具查看 二进制日志的格式STATEMENT基于段的格式binlog_format=STATEMENT 优点 日志记录量相对较小，节约磁盘及网络I/O 只对一条记录修改或者插入 row格式所产生的日志量小于段产生的日志量 缺点 必须要记录上下文信息 保证语句在从服务器上执行结果和在主服务器上相同 特定函数如UUID),user) 这样非确定性函数还是无法复制 ROW基于行的日志格式binlog_format=ROW 同—SQL语句修改了10000条数据的情况下 基于段的日志格式只会记录这个SQL语句 基于行的日志会有10000条记录分别记录每一行的数据修改 优点 使MySQL主从复制更加安全 对每一行数据的修改比基于段的复制高效 可以分析二进制日志恢复数据 缺点 记录日志量较大. binlog_row_image =[FULL[MINIMAL|NOBLOB] MIXED混合日志格式binlog_format= MIXED 特点 根据SQL语句由系统决在基于段和基于行的日志格式中进行选择 数据量的大小由所执行的SQL语句决定 如何选择二进制日志的格式建议Binlog_format=mixed or Binlog_format=row Binlog_row_image=minimal MySQL二进制日志格式对复制的影响主库复制模式 基于SQL语句的复制（SBR）优点 生成的日志量少，节约网络转输I/O 并不强制要求主从数据库的表定义完全相同 相比于基于行的复制方式更为灵活 缺点 对于非确定性事件，无法保证主从复制数据的一致性 （GUID） 对于存储过程，触法器，自定义函数进行的修改也可能造成数据不一致 相比于基于行的复制方式在从上执行时需要更多的行锁 基于行的复制（RBR）优点 可以应用于任何SQL的复制包括非确定函数，存储过程等 可以减少数据库锁的使用 缺点 要求主从数据库的表结构相同，否则可能会中断复制 无法在从上单独执行触法器 MySQL复制工作方式 主将变更写入二进制日志 从读取主的二进制日志变更并写入到relay_log中 在从上重放relay_log中的日志 基于SQL段的日志是在从库上重新执行记录的SQL 基于行的日志则是在从库上直接应用对数据库行的修改 基于GTID复制的优缺点MySQL复制拓扑 什么是高可用高可用性H.A. ( High Availability )指的是通过尽量缩短因日常维护操作(计划)和突发的系统崩溃（非计划**)所导致的停机时间，以提高系统和应用的可用性。** 可用性计算： (365*24860 ) *(1-0.99999 ) =5.256 避免导致系统不可用的因素，减少系统不可用的时间 建立完善的监控及报警系统 对备份数据进行恢复测试 正确配置数据库环境 对不需要的数据进行归档和清理 增加系统冗余，保证发生系统不可用时可以尽快修复 避免存在单点故障 主从切换及故障转移 如何避免MySQL单点故障 MMM架构数据库索引优化索引优化是对查询性能优化最有效的手段 MySQL中，存储引擎现在索引找到对应值，然后根据匹配的索引记录找到对应的数据行。 1SELECT first_name FROM sakila.actor WHERE actor_id &#x3D; 5; 如果在actor_id列上建有索引，则 MySQL将使用该索引找到actor_id为5的行，也就是说，MySQL先在索引上按值进行查找，然后返回所有包含该值的数据行。 索引可以包含一个或多个列的值。如果索引包含多个列，那么列的顺序也十分重要，因为MySQL 只能高效地使用索引的最左前缀列。创建一个包含两个列的索引，和创建两个只包含一列的索引是大不相同的。 使用ORM仍然需要关心索引 索引的类型B-Tree索引不过底层的存储引擎可能使用不同的存储结构，例如，NDB集群存储引擎内部实际上使用了T-Tree结构存储这种索引，即使其名字是BTREE ; InnoDB则使用的是B+Tree。 索引对多个值进行排序的依据是CREATE TABLE 语句中定义索引时列的顺序 可以使用B-Tree索引的查询类型。B-Tree索引适用于全键值、键值范围或键前缀查找。其中键前缀查找只适用于根据最左前缀的查找。前面所述的索引对如下类型的查询有效。 全值匹配全值匹配指的是和索引中的所有列进行.匹配，例如前面提到的索引可用于查找姓名为Cuba Allen、出生于1960-01-01的人。 匹配最左前缀前面提到的索引可用于查找所有姓为Allen 的人，即只使用索引的第一列。 匹配列前缀也可以只匹配某一列的值的开头部分。例如前面提到的索引可用于查找所有以J开头的姓的人。这里也只使用了索引的第一列。 匹配范围值例如前面提到的索引可用于查找姓在Allen和Barrymore之间的人。这里也只使用了索引的第一列。 精确匹配某一列并范围匹配另外一列前面提到的索引也可用于查找所有姓为Allen，并且名字是字母K开头（比如Kim、Karl等)的人。即第一列last_name全匹配，第二列first_name范围匹配。 只访问索引的查询B-Tree通常可以支持“只访问索引的查询”，即查询只需要访问索引，而无须访问数据行。后面我们将单独讨论这种“覆盖索引”的优化。 因为索引树中的节点是有序的，所以除了按值查找之外，索引还可以用于查询中的ORDER BY操作（按顺序查找)。一般来说，如果 B-Tree可以按照某种方式查找到值，那么也可以按照这种方式用于排序。所以，如果ORDER BY子句满足前面列出的几种查询类型，则这个索引也可以满足对应的排序需求。 下面是一些关于B-Tree索引的限制:如果不是按照索引的最左列开始查找，则无法使用索引。例如上面例子中的索引无法用于查找名字为Bill的人，也无法查找某个特定生日的人，因为这两列都不是最左数据列。类似地，也无法查找姓氏以某个字母结尾的人。 不能跳过索引中的列。也就是说，前面所述的索引无法用于查找姓为Smith并且在某个特定日期出生的人。如果不指定名(first_name)，则 MySQL只能使用索引的第一列。 如果查询中有某个列的范围查询，则其右边所有列都无法使用索引优化查找。例如有查询WHERE last_name=’Smith’ AND first_name LIKE ‘J%’AND dob = ‘1976-12-23’，这个查询只能使用索引的前两列，因为这里LIKE是一个范围条件（但是服务器可以把其余列用于其他目的)。如果范围查询列值的数量有限，那么可以通过使用多个等于条件来代替范围条件。在本章的索引案例学习部分，我们将演示一个详细的案例。 所以，索引的列的顺序很重要 哈希索引基于哈希表，对于每一行数据，存储引擎会对所有的索引列计算一个哈希值。哈希索引将所有的哈希码存储在索引中，同时在哈希表中保存指向每个数据行的指针。 在MySQL中，只有Memory引擎显式支持哈希索引。这也是Memory引擎表的默认索引类型。 哈希索引的限制 哈希索引只包含哈希值和行指针，而不存储字段值，所以不能使用索引中的值来避免读取行。不过，访问内存中的行的速度很快，所以大部分情况下这一点对性能的影响并不明显。 哈希索引数据并不是按照索引值顺序存储的，所以也就无法用于排序。 哈希索引也不支持部分索引列匹配查找，因为哈希索引始终是使用索引列的全部内容来计算哈希值的。例如,在数据列(A,B)上建立哈希索引,如果查询只有数据列A,则无法使用该索引。 哈希索引只支持等值比较查询，包括=、IN()、&lt;&gt;(注意◇&gt;和&lt;=&gt;是不同的操作)。也不支持任何范围查询，例如 WHERE price &gt; 100。 访问哈希索引的数据非常快，除非有很多哈希冲突（不同的索引列值却有相同的哈希值)。当出现哈希冲突的时候，存储引擎必须遍历链表中所有的行指针，逐行进行比较,直到找到所有符合条件的行。 如果哈希冲突很多的话，一些索引维护操作的代价也会很高。例如，如果在某个选择性很低（哈希冲突很多）的列上建立哈希索引，那么当从表中删除一行时，存储引擎需要遍历对应哈希值的链表中的每一行，找到并删除对应行的引用，冲突越多，代价越大。 空间数据索引（R-TREE）MyISAM表支持空间索引，可以用作地理数据存储。 全文索引全文索引是一种特殊类型的索引，它查找的是文本中的关键词，而不是直接比较索引中的值。全文搜索和其他几类索引的匹配方式完全不一样。它有许多需要注意的细节，如停用词、词干和复数、布尔搜索等。全文索引更类似于搜索引擎做的事情，而不是简单的 WHERE条件匹配。 其他索引索引的优点三大优点： 索引大大减少了服务器需要扫描的数据量。 索引可以帮助服务器避免排序和临时表。 索引可以将随机I/O变为顺序IO。 高性能的索引策略独立的列索引不能是表达式的一部分，也不能是函数的参数。 例如，下面这个查询无法使用actor_id列的索引: 1mysql&gt; SELECT actor_id FROM sakila.actor MHERE actor_id + 1 &#x3D;5; 下面是另一个常见的错误: 1mysql&gt; SELECT ... WHERE TO_DAYS(CURRENT_DATE) - TO_DAYS(date_col) &lt;&#x3D; 10; 前缀索引和索引选择性对于很长的字符列，可以索引开始的部分字符。（节省索引空间和提高索引效率），但也会降低索引的选择性。 对于BLOG、TEXT、或者很长的VARCHAR类型的列，必须使用前缀索引。 1CREATE INDEX index_name ON table(col_name(n)); #n有限制 联合索引为每个列创建独立的索引或者按照错误的顺序创建多列索引并不能提高效率。 如何选择索引列的顺序 经常会被使用到的列 优先选择性高的列优先 宽度小的列优先 尝试使用索引合并 聚簇索引聚簇索引并不是一种单独的索引类型，而是一种数据存储方式。具体的细节依赖于其实现方式，但InnoDB的聚簇索引实际上在同一个结构中保存了B-Tree索引和数据行。 覆盖索引覆盖索引（covering index）指一个查询语句的执行只用从索引中就能够取得，不必从数据表中读取。也可以称之为实现了索引覆盖。 如果一个索引包含了（或覆盖了）满足查询语句中字段与条件的数据就叫做覆盖索引。 使用索引扫描来做排序 索引的列顺序和Order By子句的顺序完全一致 索引中所有列的方向(升序,降序)和Order by子句完全一致 Order by中的字段全部在关联表中的第一张表中 模拟Hash索引优化查询 （使用BTree索引模拟Hash） 只能处理键值的全值匹配查找 所使用的Hash函数决定着索引键的大小 利用索引优化锁 索引可以减少锁定的行数 索引可以加快处理速度，同时也加快了锁的释放 压缩冗余和重复索引 1pt-duplicate-key-checker h&#x3D;127.0.0.1 #排查冗余索引 查找未使用的索引123456SELECT object_schema, object_name, index_name,b.TABLE_RO\\FROM performance_schema.table_io_waits_summary_by_index_usage a JOIN information_schema.tables b ONa.OBJECT_SCHEMA&#96;&#x3D;b.TABLE_SCHEMA&#96;AND a.OBJECT_NAME&#96;&#x3D; b.TABLE_NAMEWHERE index_name IS NOT NULLAND count_star &#x3D; 0ORDER BY object_schema, object_name; 更新索引的统计信息及减少索引碎片12analyze table table_nameoptimize table table_name #会导致锁表 SQL查询优化查询优化，索引优化，库表结构优化需要齐头并进。 如何获取有性能问题的SQL 通过用户反馈获取存在性能问题的SQL 通过慢查日志获取存在性能问题的SQL 实时获取存在性能问题的SQL 慢查询日志介绍存储日志所需要的大量的磁盘空间 slow_query_log on/off 启动停止记录慢查日志 可以通过脚本定时开关 slow_query_log_file 指定慢查日志的存储路径及文件 long_query_time 指定记录慢查日志SQL执行时间的伐值 log_queries_not_using_indexes 是否记录未使用索引的SQL 会记录哪些语句？ 记录所有符合条件的SQL 包括查询语句 数据修改语句 已经回滚的SQL 常用的慢查日志分析工具 (mysqldumpslow)1mysqldumpslow -s r -t 10 slow-mysql.log 实时获取性能问题SQL 12SELECT id, user , host,DB,command, time ,state, info FROM information_schema.PROCESSLISTWHERE TIME &gt;&#x3D; 60 SQL的解析预处理及生成执行计划查询为什么会慢（MySQL服务器处理查询请求的过程）？ 客户端发送SQL请求给服务器 服务器检查是否可以在查询缓存中命中该SQL （HASH） 服务器端进行SQL解析，预处理，再由优化器生成对应的执行计划 跟据执行计划，调用存储引擎API来查询数据 将结果返回给客户端 对于一个读写频繁的系统使用查询缓存很可能会降低查询处理的效率 query_cache_type 设置查询缓存是否可用 query_cache_size 设置查询缓存的内存大小 query_cache_limit 设置查询缓存可用存储的最大值 query_cache_wlock_invalidate 设置数据表被锁后是否返回缓存中的数据 query_cache_min_res_unit 设置查询缓存分配的内存块最小单位 如何确定查询处理各个阶段所消耗的时间使用profile set profiling =1; 执行查询 show profiles; 查看每一个查询所消耗的总时间的信息 show profile for query N;查询的每个阶段所消耗的时间 show profile cpy for query N 使用performance_schema（建议）启动 123update setup_instruments SET enabled&#x3D;&#39;YES&#39;, TIMED&#x3D;&#39;YES&#39; WHERE NAME LIKE &#39;stage&#39;UPDATE setup_consumers SET enabled&#x3D;&#39;YES&#39; WHERE NAME LIKE &#39;events%&#39;; 使用 1234567SELECT a.THREAD_ID, SQL_TEXT,c.EVENT_NAME, (C.TIMER_END - c.TIMER_START)&#x2F;1000000000 AS &#39;DURATION (ms)&#39;FROM events_statements_history_long aJOIN threads b ON a.THREAD_ID&#x3D; b.THREAD_IDJOIN events_stages_history_long c ON c.THREAD_ID&#x3D; b.THREAD_IDAND c.EVENT_ID BETWEEN a.EVENT_ID AND a.END_EVENT_IDWHERE b.PROCESSLIST_ID&#x3D;CONNECTION_ID() AND a.EVENT_NAME&#x3D; &#39;statement&#x2F;sql&#x2F;select&#39; ORDER BY a.THREAD_ID,C.EVENT_ID 特定SQL的查询优化大表的更新和删除12345678910111213141516DELIMITER $$USE &#96;imooc&#96;$$DROP PROCEDURE IFEXISTS &#96;p_delete_rows&#96; $$CREATE DEFINER&#x3D;&#39;root&#39;127.0.0.1&#39; PROCEDURE &#39;p_delete_rows&#96; ()BEGIN DECLARE v_rows INT; SET v_rows &#x3D; 1; WHILE v _rows &gt;0 DO DELETE FROM sbtest1 WHERE id &#x3D; 90000 AND id &lt;&#x3D; 19000q LIMIT 5000; SELECT ROW_COUNT( INTO v_rows; SELECT SLEEP(5); END WHILE;END$$DELIMITER ; 如何修改大表的结构 对表中的列的字段类型进行修改 改变字段的宽度时还是会锁表 无法解决主从数据库延迟的问题 使用主从结构 or 12pt-online-schema-change \\--alter&#x3D;&quot;MODIFY c VARCHAR(150)NOT NULL DEFAULT&quot;&quot; \\--user&#x3D;root --password&#x3D;PassWord D&#x3D;imooc,t&#x3D;sbtest4 \\--charset&#x3D;utf8 --execute 数据库的分库分表分库 分片 如何选择分区键 分区键要能尽量避免跨分片查询的发生 分区键要能尽量使各个分片中的数据平均 如何存储无需分片的表 每个分片中存储一份相同的数据 使用额外的节点统一存储 如何在节点上部署分片 每个分片使用单一数据库，并且数据库名也相同 将多个分片表存储在一个数据库中，并在表名上加入分片号后缀 在一个节点中部署多个数据库，每个数据库包含一个分片 如何分配分片中的数据 按分区键的Hash值取模来分配分片 数据按分区键的范围来分配分片数据 利用分区键和分片的映射表来分配分片数据 如何生成全局唯一ID 使用auto_increment_increment和auto_increment_offset参数 使用全局节点来生成ID 在Redis等缓存服务器中创建全局ID 数据库监控","categories":[{"name":"Mysql","slug":"Mysql","permalink":"http://www.postman.life/categories/Mysql/"}],"tags":[]},{"title":"MySQL必知必会笔记","slug":"MySQL必知必会笔记","date":"2020-11-17T14:39:02.463Z","updated":"2021-06-14T13:59:18.857Z","comments":true,"path":"2020/11/17/MySQL必知必会笔记/","link":"","permalink":"http://www.postman.life/2020/11/17/MySQL%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A%E7%AC%94%E8%AE%B0/","excerpt":"","text":"[TOC] 基础知识与命令表名：相同数据库中不能两次使用相同的表明、不同的数据库中可以 列: 表中的一个字段、所有表都是由一个或多个列组成 数据类型： 所容许的数据的类型，每个表列都有相应的数据类型 行：表中的一行记录 主键： 一列或一组列，它的值能够唯一区分表中每个行、标识自己的一列。应该总是定义主键，虽然并不总是都需要 任何列都可以作为主键，只要满足以下条件： 任意两行都不具有相同的主键值； 每个行都必须具有一个主键值（主键列不允许为NULL值） 主键的最好习惯： 除了MySQL强制实施的规则外，应该坚持的几个普遍认可的最好习惯： 不更新主键列中的值 不重用主键列的值 不在主键列中使用可能会更改的值 命令输入在mysql&gt;之后命令用;或\\g结束，仅按Enter不执行命令为了使用crashcourse 数据库，应该输入以下内容:use crashcourse 返回可用数据库的一个列表show databases 返回可用数据库的一个列表show tables; 返回字段信息show columns from customers show index from table_name show status 显示广泛的服务器状态信息 show create database 和 show create table 分别用来显示创建特定数据库或表的MySQL语句 show grants 用来显示授予用户（所有用户或特定用的安全权限） show errors 和 show warnings 用来显示服务器错误或警告消息 主键索引(BTree)Select 查询限制结果select * from emp limit 5 返回不多于5行 select * from emp limit 5,5 返回从行5开始的5行 （第一个数为开始位置，第二数为要检索的行数） 排序默认排序select prod_name from products order by prod_name 按多个列排序,首先按价格，然后再按名称排序select prod_id,prod_price,prod_name from products order by prod_price,prod_name 指定排序方向数据排序不限于升序，A-Z，这是默认的排序顺序，还可以使用DESC进行降序排序select prod_id,prod_price,prod_name from products order by prod_price desc,prod_name DESC只作用于其前面的列名，如果对剩下的列名不指定，仍然按默认排序 使用ORDER BY和LIMIT组合，找出一个列中最高或最低值select prod_price from products order by prod_price DESC LIMIT 1; 过滤数据使用WHERE子句select prod_name, prod_price from products where prod_price = 2.50; WHERE子句操作符 操作符 说明 = 等于 &lt;&gt; 不等于 != 不等于 &lt; 小于 &lt;= 小于等于 &gt; 大于 &gt;= 大于等于 BETWEEN 在指定的两个值之间 where prod_name = ‘fuses’ ，MySQL在执行匹配时默认不区分大小写，所以fuses于Fuses匹配 BETWEEN 用法：BETWEEN 5 AND 10，表示检索的数字在5和10之间 空值检查 NULL，它与字段包含0、空字符串或仅仅包含空格不同IS NULL、IS NOT NULL AND 操作FROM EMP WHERE CONDITION1 AND CONDITION2 OR 操作FROM EMP WHERE CONDITION1 OR CONDITION2 Tips：在处理OR操作符前，优先处理AND操作符IN 操作FROM EMP WHERE CONDITION1 IN (‘’, ‘’) NOT 操作FROM EMP WHERE CONDITION1 NOT IN (‘’, ‘’) 通配符 LIKE百分号（%）通配符 匹配后面任意字符LIKE ‘jet%’ 下划线（_）通配符 匹配单个字符LIKE ‘_ ton’ 正则表达式前置知识()小括号捕获组用于捕获匹配的字符串，匹配小括号内的字符串，可以是一个，也可以是多个，常跟“|”（或）符号搭配使用，是多选结构的。例如：(abc|cbd)匹配的是abc或者cbd都能匹配，多选，可以写多个 []中括号匹配字符组内的字符，比如咱们常用的[0-9a-zA-Z.?!]等，在[]内的字符都是字符，不是元字符，比如0-9、a-z这中间的 “-” 就是连接符号，表示范围的元字符，如果写成[-!?(]这样的话，就是普通字符例如：[1,2,3,a-z]能匹配1、2、3、a到z的字符 {}大括号大括号{}：匹配次数，匹配在它之前表达式匹配出来的元素出现的次数，{n}出现n次、{n,}匹配最少出现n次、{n,m}匹配最少出现n次，最多出现m次例如：[a-z]{1,2}能匹配1个或者2个小写字母或者是(abc){1,2}能匹配到abc或者abcabc REGEXP选择匹配包含本文’17’的所有行 select id_number from tsc where id_number REGEXP ‘17’ 看上去似乎LIKE差不多，可能还会降低性能，不过请考虑下面例子： select id_number from tsc where tsc.id_number REGEXP ‘.000’ 这里使用了正则表达式.000,是正则表达式中的一个特殊的字符，它表示匹配任意一个字符。 因为1000和2000都匹配且返回 OR匹配select id_number from tsc where id_number REGEXP ‘1000|2000’ 该句使用了正则表达式1000|2000， **|**为正则表达式的OR操作符，它表示匹配其中之一 使用**|**从功能上类似在select语句中使用OR语句，多个OR条件可以并入单个正则表达式 两个以上的OR条件： 可以给两个以上的OR条件，例如，’1000|2000|3000’ 匹配几个字符之一 匹配任意单一字符。但是，如果你只想匹配特定的字符，使用指定一组**[和]**括起来的字符来完成。 REGEXP ‘[123] Ton’ [123]定义一组字符，它的意思是匹配1或2火3， 因此，1 Ton和2 Ton都匹配且返回，没有3 Ton 匹配范围[0123456789] 为了简化这种类型的集合，可以使用**-**来定义一个范围 [0-9] 等同于上述数字列表 范围不限于完整的集合[1-3]和[6-9]也是合法的，此外，[a-z]匹配任意字母字符 示例：REGEXP ‘[1-3] Ton’ 匹配特殊字符正则由具有特定含义的特殊字符组成，我们已经看到 . 、**[]** 、**|** 和 -**，还有其他一些字符，请问如果你需要匹配这些字符，应该怎么办？例如要找到包含.**字符的值 为了匹配这些特殊字符，必须使用 \\作为前导 ， \\\\-表示查找- ······· 空白元字符 元字符 说明 \\\\f 换页 \\\\n 换行 \\\\r 回车 \\\\t 制表 \\\\v 纵向制表 为了匹配反斜杠\\字符本身，需要使用\\\\\\ 匹配字符类存在找出你自己经常使用的数字、所有字母字符或所有数字字母字符等的匹配。为更方便工作，可以使用预定义的字符集，称为字符类(character class)。 类 说明 [:alnum:] 任意字母和数字(同[a-zA-Z0-9]) [:alpha:] 任意字符(同[a-zA-Z]) [:blank:] 空格和制表(同\\t) [:cntrl:] ASCII控制字符(ASCII 0到31和127) [:digit:] 任意数字(同[0-9]) [:graph:] 与[:print:]相同，但不包括空格 [:lower:] 任意小写字母[同[a-z]] [:print:] 任意可打印字符 [:punct:] 即不在[:alnum:]又不在[:cntrl:]中的任意字符 [:space:] 包括空格在内的任意空白字符(同[\\\\f\\\\n\\\\r\\\\t\\\\v]) [:upper:] 任意大写字母(同[A-Z]) [:xdigit:] 任意十六进制数字(同[a-fA-F0-9]) 匹配多个实例目前为止使用的所有正则表达式都试图匹配单次出现。如果存在一个匹配，该行被检索出来，如果不存在，检索不出任何行。但有时需要对匹配的数目进行更强的控制。例如，你可能需要寻找所有的数，不管数中包含多少数字，或者你可能想寻找一个单词并且还能够适应一个尾随的s（如果存在)，等等。 重复元字符 元字符 说明 * 0个或多个匹配 + 1个或多个匹配(等于{1,}) ？ 0个或1个匹配(等于{0,1}) {n} 指定数目的匹配 {n,} 不少于指定数目的匹配 {n,m} 匹配数目的范围(m不超过255) 例子一：select id_number from tsc where id_number REGEXP ‘\\([0-9] sticks?\\)’ 正则表达式\\([0-9] sicks?\\)， \\\\(匹配)， [0-9] 匹配任意数字，sticks?匹配stick和sticks(s后的?使s可选)，因为?匹配它前面的任何字符的0次或1次出现)， \\?匹配)。没有？匹配stick和sticks会非常困难。 例子二: select id_number from tsc where id_number REGEXP ‘[[:digit:]]{4}’ 它匹配任意数字。因而它为数字的一个集合。{4}确切地要求它前面的字符( 任意数字)出现4次。 定位符定位元字符 元字符 说明 ^ 文本的开始 $ 文本的结尾 [[:&lt;:]] 词的开始 [[:&gt;:]] 词的结尾 如果你想找出以一个数(包括以小数点开始的数)开始的所有产品，怎么？简单搜索[0-9\\.] 或 [[:digit:]\\.]不行，因为它将在文本内任意位置查找匹配。解决办法是使用^定位符 select id_number from tsc where id_number REGEXP ‘^[0-9\\.]’ ^的双重用途 ^有两种用法。在集合中(用[和]定义)，用它来否定该集合，否则用来指串的开始处。 LIKE 匹配整个串而REGEXP匹配字串 简单的正则表达式测试可以在不使用数据库表的情况下用选择来测试正则表达式。REGEXP检查总是返回0(没有匹配)或1(匹配))。可以用带文字串的REGEXP来测试表达式并试验它们.相应的语法如下：选择 SELECT ‘HELLO’ REGEXP ‘[0-9]’, 这个例子显然将返回0（因为文本HELLO中没有数字） 创建计算字段拼接字段将值连接到一起构成单个值 可使用Concat()函数来拼接两个列 SELECT Concat(id, id_number) FROM TSC 删除数据右侧多余的空格select CONCAT(RTRIM(id ), id_number) from tsc 拼接前删除id右侧多余空格 select RTRIM(CONCAT(id, id_number ) ) from tsc 拼接后删除右侧多余空格 使用别名(alias)AS 别名有时也称为到处列 使用别名的两个主要理由： 缩短SQL语句。 允许在一条SELECT语句中多次使用相同的表。 12345SELECT cust_name, cust_contact FROM Customers AS C, Orders AS O, OrderItems AS OIWHERE C.cust_id &#x3D; O.cust_idAND OI.order_num &#x3D; O.order_numAND prod_id &#x3D; &#39;RGAN01&#39;; 别名不仅能用于WHERE子句，还可以用于SELECT列表、ORDER BY子句以及其他语句部分。 执行算术计算Select prod_id, quantity, item_price, quantity*item_price AS expanded_price FROM TSC MySQL算术操作符 操作符 说明 + 加 - 减 * 乘 / 除 使用数据处理函数使用函数SQL支持利用函数来处理数据。函数一般是在数据上执行的 大多数SQL实现支持以下类型的函数： 用于处理文本串（删除、填充值、转换值为大写或小写）的文本函数。 用于在数值数据上进行算术操作（如返回绝对值，进行代数运算)的数值函数。 用于处理日期和时间值并从这些值中提取特定成分（例如，返回两个日期之差，检查日期有效性等）的日期和时间函数。 返回DBMS正使用的特殊信息（如返回用户登录信息，检查版本细节)的系统函数。 文本处理函数RTrim()、Upper() Select prod_id, quantity, Upper(item_price), quantity*item_price AS expanded_price FROM TSC 常用的文本处理函数 函数 说明 Left() 返回串左边的字符 Length() 返回串的长度 Locate() 找出串的一个子串 Lower() 将串转换为小写 LTrim() 去掉串左边的空格 Right() 返回串右边的字符 RTrim() 去掉串右边的空格 Soundex() 返回串的SOUNDEX值 SubString() 返回子串的字符 Upper 将串转换为大写 日期和时间处理函数 函数 说明 AddDate() 增加一个日期（天、周等) AddTime() 增加一个时间(时、分等) CurDate() 返回当前日期 CurTime() 返回当前时间 Date() 返回日期时间的日期部分 DateDiff() 计算两个日期之差 Date_Add() 高度灵活的日期运算函数 Date_Format() 返回一个格式化的日期或时间串 Day() 返回一个日期的天数部分 DaofOfWeek() 对于一个日期，返回对应的星期几 Hour() 返回一个时间的小时部分 Minute() 返回一个时间的分钟部分 Month() 返回一个日期的月份部分 Now() 返回当前日期和时间 Second() 返回一个时间的秒部分 Time() 返回一个日期时间的时间部分 Year() 返回一个日期的年份部分 注意MySQL使用的日期格式，无论你什么时候指定一个日期，不管是插入或更新表值还是用WHERE子句进行过滤，日期必须为格式yyyy-mm-dd。因此，2005年9月1日，给出为2005-09-01.虽然其他的日期格式可能也行，但这是首选的日期格式，因为它排除了多义性（如，04/05/6是2006年5月4日或2006年4月5日或2004年5月6日或·····） 应该总是使用4位数字的年份 支持2位数字的年份,MySQL处理00-69为2000-2069，处理70-99为1970-1999。虽然它们可能是打算要的年份,但使用完整的4位数字年份更可靠，因为·MySQL不必做出任何假定。 *select * from tsc where order_date = ‘2005-09-01’* 但是，使用WHERE order_date = ‘2005-09-01’可靠吗? order_ date的数据类型为datetime。这种类型存储日期及时间值。样例表中的值全都具有时间值00:00:00,但实际中很可能并不总是这样。如果用当前日期和时间存储订单日期（因此你不仅知道订单日期，还知道下订单当天的时间)，怎么办?比如，存储的order_date值为2005-09-01 11:30:05，则WHERE order date = ‘2005-09-01’失败。即使给出具有该日期的一行，也不会把它检索出来，因为WHERE匹配失败。解决办法是指示MySQL仅将给出的日期与列中的日期部分进行比较，而不是将给出的日期与整个列值进行比较。为此，必须使用Date()函数。Date(order _date)指示MySQL仅提取列的日期部分，更可靠的SELECT语句为: *select * from tsc where Date(order_date ) = ‘2005-09-01’* 如果要的是日期，请使用Date() 如果你想要的仅是日期,则使用Date()是一个良好的习惯,即使你知道相应的列只包含日期也是如此。这样,如果由于某种原因表中以后有日期和时间值,你的SQL代码也不用改变。当然，也存在一个Time()函数,在你只想要时间时应该使用它。Date()和Time()都是在MySQL 4.1.1中第一次引入的。 还有一种日期比较需要说明。如果你想检索出2005年9月下的所有订单，怎么办?简单的相等测试不行，因为它也要匹配月份中的天数。有几种解决办法,其中之一如下所示: *select * from tsc where Date(order_date ) = BETWEEN ‘2005-09-01’ AND ‘2005-09-30’* 其中，BETWEEN操作符用来把2005-09-01和2005-09-30定义为一个要匹配的日期范围。 还有另外一种办法（一种不需要记住每个月中有多少天或不需要操心闰年2月的办法): *select * from tsc where Date(order_date ) = Yead(order_date) = 2005 and Month(order_date) = 9* 数值处理函数 函数 说明 Abs() 返回一个数的绝对值 Cos() 返回一个角度的余弦 Exp() 返回一个数的指数值 Mod() 返回除操作的余数 Pi() 返回圆周率 Rand() 返回一个随机数 Sin() 返回一个角度的正弦 Sqrt() 返回一个数的平方根 Tan() 返回一个角度的正切 汇总数据聚集函数(aggregate function) 运行在行组上，计算和返回单个值的函数我们经常需要汇总数据而不用把它们实际检索出来，为此MySQL提供了专门的函数。使用这些函数，MySQL查询可用于检索数据，以便分析和报表生成。这种类型的检索例子有以下几种。 确定表中行数(或者满足某个条件或包含某个特定值的行数)。 获得表中行组的和。 找出表列(或所有行或某些特定的行）的最大值、最小值和平均值。 上述例子都需要对表中数据（而不是实际数据本身）汇总。因此，返回实际表数据是对时间和处理资源的一种浪费（更不用说带宽了)。重复一遍，实际想要的是汇总信息。为方便这种类型的检索，MySQL给出了5个聚集函数，这些函数能进行上述罗列的检索。 函数 说明 AVG() 返回某列的平均值 COUNT() 返回某列的行数 MAX() 返回某列的最大值 MIN() 返回某列的最小值 SUM() 返回某列值之和 AVG函数AVG()通过对表中行数计数并计算特定列值之和，求得该列的平均值。AVG ()可用来返回所有列的平均值，也可以用来返回特定列或行**(where条件)**的平均值。 SELECT AVG(prod_price） AS avg_price FROM products; **只用于单个列AVG() ** 只能用来确定特定数值列的平均值,而且列名必须作为函数参数给出,为了获得多个列的平均值，必须使用多个AVG()函数。 NULL值 AVG()函数忽略列值为NULL的行。 COUNT()函数COUNT()函数进行计数。可利用COUNT ()确定表中行的数目或符合特定条件的行的数目。 COUNT ()函数有两种使用方式。 使用COUNT(*)对表中行的数目进行计数,不管表列中包含的是空值（NULL）还是非空值。 SELECT COUNT( *) AS num_cust FROM customers; 使用COUNT(column)对特定列中具有值的行进行计数，忽略NULL值。 SELECT COUNT( cust_email) AS num_cust FROM customers; NULL值 如果指定列名，则指定列的值为空的行被COUNT()函数忽略,但如果COUNT()函数中用的是星号(*),则不忽略。 MAX()函数MAX()返回指定列中的最大值。MAX()要求指定列名, 对非数值数据使用MAX()虽然MAX()一般用来找出最大的数值或日期值,但MySQL允许将它用来返回任意列中的最大值，包括返回文本列中的最大值。在用于文本数据时,如果数据按相应的列排序，则MAX()返回最后一行。 NULL值 MAX()函数忽略列值为NULL的行 MIN()函数MIN()的功能正好与MAX(）功能相反，它返回指定列的最小值。与MAX()一样，MIN(）要求指定列名 对非数值数据使用MIN() MIN(）函数与MAX()函数类似,MySQL允许将它用来返回任意列中的最小值,包括返回文本列中的最小值。在用于文本数据时,如果数据按相应的列排序，则MIN()返回最前面的行。NULL值 MIN()函数忽略列值为NULL的行。SUM()函数SUM()用来返回指定列值的和（总计） NULL值 SUM()函数忽略列值为NULL的行。 利用标准的算术操作符，所有聚集函数都可用执行多个列上的计算聚集不同值DISTINCT 以上5个聚集函数都可以如下使用: 对所有的行执行计算，指定ALL参数或不给参数(因为ALL是默认行为); 只包含不同的值，指定DISTINCT参数。 ALL为默认ALL参数不需要指定,因为它是默认行为。如果不指定DISTINCT,则假定为ALL。下面的例子使用AVG ()函数返回特定供应商提供的产品的平均价格。它与上面的SELECT语句相同，但使用了DISTINCT参数，因此平均值只考虑各个不同的价格: SELECT AVG(DISTINCT prod_price) AS avg price FROM products WHERE vend_id = 1003; 注意 如果指定列名,则DISTINCT只能用于COUNT(). DISTINCT不能用于COUNT(*),因此不允许使用COUNT (DISTINCT) ，,否则会产生错误。类似地,DISTINCT必须使用列名，不能用于计算或表达式。 将DISTINCT用于MIN()和MAX() 虽然DISTINCT从技术上可用于MIN()和MAX(),但这样做实际上没有价值。一个列中的最小值和最大值不管是否包含不同值都是相同的。 组合聚集函数目前为止的所有聚集函数例子都只涉及单个函数。但实际上SELECT语句可根据需要包含多个聚集函数。请看下面的例子: SELECT COUNT(*) AS num_items,MIN(prod_price) AS price_min,MAX (prod_price) AS price_max,AVG(prod_price) AS price_avgFROM products; 这里用单条SELECT语句执行了4个聚集计算，返回4个值(products表中物品的数目，产品价格的最高、最低以及平均值)。 取别名 在指定别名以包含某个聚集函数的结果时,不应该使用表中实际的列名,虽然这样做并非不合法,但使用唯一的名字会使你的SQL更易于理解和使用(以及将来容易排除故障）. 分组数据本章将介绍如何分组数据,以便能汇总表内容的子集。这涉及两个新SELECT语句子句，分别是GROUP BY子句和HAVING子句。 从上一章知道，SQL聚集函数可用来汇总数据。这使我们能够对行进行计数，计算和与平均数，获得最大和最小值而不用检索所有数据。 目前为止的所有计算都是在表的所有数据或匹配特定的WHERE子句的数据上进行的。提示一下，下面的例子返回供应商1003提供的产品数目: *SELECT COUNT() AS num_prods FROM products WHERE vend_id = 1003;** 但如果要返回每个供应商提供的产品数目怎么办?或者返回只提供单项产品的供应商所提供的产品，或返回提供10个以上产品的供应商怎么办? 这就是分组显身手的时候了。分组允许把数据分为多个逻辑组，以便能对每个组进行聚集计算。 创建分组GROUP BY SELECT vend_id, COUNT(*) AS num_prods FROM products GROUP BY vend_id; 上面的SELECT语句指定了两个列，vend_id包含产品供应商的ID，num prods为计算字段(用COUNT(*)函数建立)。GROUP BY子句指示MySQL按vend_id排序并分组数据。这导致对每个vend_id而不是整个表计算num _prods一次。 在具体使用GROUP BY子句前，需要知道一些重要的规定。 GROUP BY子句可以包含任意数目的列。这使得能对分组进行嵌套，为数据分组提供更细致的控制。 如果在GROUP BY子句中嵌套了分组，数据将在最后规定的分组上进行汇总。换句话说，在建立分组时，指定的所有列都一起计算(所以不能从个别的列取回数据)。 GROUP BY子句中列出的每个列都必须是检索列或有效的表达式 (但不能是聚集函数)。 如果在SELECT中使用表达式，则必须在GROUP BY子句中指定相同的表达式。不能使用别名。 除聚集计算语句外，SELECT语句中的每个列都必须在GROUP BY子句中给出。 如果分组列中具有NULL值，则NULL将作为一个分组返回。如果列中有多行NULL值,它们将分为一组。 GROUP BY子句必须出现在WHERE子句之后，ORDER BY子句之前。 使用ROLLUP使用WITH ROLLUP关键字, 可以得到每个分组以及每个分组汇总级别(针对每个分组)的值,如下所示: SELECT vend_id，COUNT(*) AS num_prods FROM products GROUP BY vend id WITH ROLLUP;过滤分组除了使用GROUP BY分组数据，MySQL还允许过滤分组。规定包括哪些分组，排除哪些分组 我们已经看到了WHERE子句的作用（第6章中引入)。但是，在这个例子中WHERE不能完成任务，因为WHERE过滤指定的是行而不是分组。事实上，WHERE没有分组的概念。 使用HAVING（HAVING支持所有的WHERE操作符） SELECT cust_id，COUNT() AS orders FROM orders GROUP BY cust_id HAVING COUNT() &gt;- 2; 它过滤COUNT(*) &gt;= 2 (两个以上的订单)的那些分组 分组和排序虽然GROUP BY和ORDER BY经常完成相同的工作，但它们是非常不同的。 ORDER BY GROUP BY 排序产生的输出 分组行。但输出可能不是分组的排序 任意列都可以使用（甚至非选择的列也可以使用） 只可能使用选择列或表达式列，而且必须使用每个选择列表达式 不一定需要 如果与聚集函数一起使用列（或表达式），则必须使用 不要忘记ORDER BY 一般在使用GROUP BY子句时，应该也给出ORDER BY子句。这是保证数据正确排序的唯一方法，千万不要仅依赖GROUP BY排序数据。 SELECT子句顺序 子句 说明 是否必须 SELECT 要返回的列或表达式 是 FROM 从中检索数据的表 仅在从表选择数据时使用 WHERE 行级过滤 否 GROUP BY 分组说明 仅在按组计算聚集时使用 HAVING 组级过滤 否 ORDER BY 输出排序顺序 否 使用子查询查询（query）：任何SQL语句都是查询，但一般指SELECT语句。 SQL还允许创建子查询（subquery），即嵌套在其他查询中的查询。 使用子查询进行过滤订单存储在连个表中。每个订单包含订单编号、顾客ID、订单日期，在Orders表中存储为一行，各订单的物品存储在相关的OrderItems表中。Orders表不存储顾客信息，只存储顾客ID。顾客的实际信息存储在Customers表中。 现在，假如需要列出订购物品RGAN01的所有顾客，应该怎样检索？下面列出具体的步骤。 检索包含物品RGAN01的所有订单的编号。 检索具有前一步骤列出的订单的所有顾客的ID。 检索前一步骤返回的所有顾客ID的顾客信息。 三步:1234567891011SELECT order_num FROM OrderItemsWHERE prod_id &#x3D; &#39;RGAN01&#39;;SELECT cust_id FROM OrdersWHERE order_num IN (20007, 20008);SELECT cust_name, cust_contact FROM CustomersWHERE cust_id IN (&#39;1000000004&#39;, &#39;1000000005&#39;); 合并成一句:1234567SELECT cust_name, cust_contact FROM CustomersWHERE cust_id IN ( SELECT cust_id FROM Orders WHERE order_num IN ( SELECT order_num FROM OrderItems WHERE prod_id &#x3D; &#39;RGAN01&#39;)); 格式化SQL 包含子查询的SELECT语句难以阅读和调试，特别是它们较为复杂时更是如此。如上所示把子查询分解为多行并且适当地进行缩进,能极大地简化子查询的使用。 **列必须匹配 ** 在WHERE子句中使用子查询(如这里所示),应该保证SELECT语句具有与WHERE子句中相同数目的列。通常,子查询将返回单个列并且与单个列匹配,但如果需要也可以使用多个列。 子查询和性能 这里给出的代码有效并获得所需的结果。但是，使用子查询并不总是执行这种类型的数据检索的最有效的方法。 作为计算字段使用子查询使用子查询的另一个方法是创建计算字段。 假如需要显示Customers表中每个顾客的订单总数。订单与相应的顾客ID存储在Orders表中。 执行这个操作，要遵循下面的步骤： 从Customers表中检索顾客列表。 对于检索出的每个顾客，统计其在Orders表中的订单数目。 123456SELECT cust_name, cust_state, ( SELECT COUNT(*) FROM Orders WHERE Orders.cust_id &#x3D; Customers.cust_id ) AS ordersFROM CustomersORDER BY cust_name; 联结表Join关系表关系表的设计就是要把信息分解成多个表，一类数据一个表，各表通过某些共同的值互相关联（所以才叫关系数据库）。 外键(foreign key) 外键为某个表中的一列,它包含另一个表的主键值，定义了两个表之间的关系。 创建联结123SELECT vend_name, prod_name, prod_priceFROM Vendors, ProductsWHERE Vendors.vend_id &#x3D; Products.vend_id; 不要忘了WHERE子句 应该保证所有联结都有WHERE子句,否则MySQL将返回比想要的数据多得多的数据。同理,应该保证WHERE子句的正确性。不正确的过滤条件将导致MySQL返回不正确的数据。 叉联结 有时我们会听到返回称为叉联结(cross join)的笛卡儿积的联结类型。 内部联结内联结（inner join）目前为止，使用的联结称为等值联结（equijoin），它基于两个表之间的相等测试。这种联结也称为内联结（inner join）。内联结是最常用的联结方式。 123SELECT vend_name, prod_name, prod_priceFROM Vendors INNER JOIN ProductsON Vendors.vend_id &#x3D; Products.vend_id; 联结多个表12345SELECT prod_name, vend_name, prod_price, quantityFROM OrderItems, Products, VendorsWHERE Products.vend_id &#x3D; Vendors.vend_idAND OrderItems.prod_id &#x3D; Products.prod_idAND order_num &#x3D; 20007; 性能考虑 MySQL在运行时关联指定的每个表以处理联结,这种处理可能是非常耗费资源的,因此应该仔细,不要联结不必要的表。联结的表越多，性能下降越厉害。 创建高级联结使用别名，参考别名部分 自联结使用表别名的主要原因之一是能在单挑SELECT语句中不止一次引用相同的表（检索的两个表实际上是同一张表） 假如要给与Jim Jones同一公司的所有顾客发送一份邮件。 方法一：子查询 12345SELECT cust_id, cust_name, cust_contactFROM CustomersWHERE cust_name &#x3D; ( SELECT cust_name FROM Customers WHERE cust_contact &#x3D; &#39;Jim Jones&#39;); 方法二：自联结查询 1234SELECT c1.cust_id, c1.cust_name, c1.cust_contactFROM Customers AS c1, Customers AS c2WHERE c1.cust_name &#x3D; c2.cust_nameAND c2.cust_contact &#x3D; &#39;Jim Jones&#39;; 用自联结而不用子查询 自联结通常作为外部语句用来替代从相同表中检索数据时使用的子查询语句。虽然最终的结果是相同的,但有时候处理联结远比处理子查询快得多。应该试一下两种方法,以确定哪一种的性能更好。 自然联结在对表进行联结时，至少有一列（被联结的列）不止出现在一个表中。标准的内联结返回所有数据，相同的列甚至多次出现。自然联结排除多次出现，使每一列只返回一次。 自然联结要求只能选择那些唯一的列，一般通过对一个表使用通配符（SELECT *），而对其他表的列使用明确的子集来完成。 123456SELECT C.*, O.order_num, O.order_date, OI.prod_id, OI.quantity, OI.item_price FROM Customers AS C, Orders AS O, OrderItems AS OIWHERE C.cust_id &#x3D; O.cust_idAND OI.order_num &#x3D; O.order_numAND prod_id &#x3D; &#39;RGAN01&#39;; 事实上，我们迄今为止建立的每个内联结都是自然联结，很可能永远都不会用到不是自然联结的内联结。 外部联结许多联结将一个表中的行与另一个表中的行相关联，但有时候需要包含没有关联的那些行。 例如： 对每个顾客下的订单进行计数，包括哪些至今尚未下订单的顾客。 列出所有产品以及订购数量，包括没有人订购的产品。 计算平均销售规模，包括哪些至今尚未下订单的顾客。 在上述例子中，联结包含了那些在相关表中没有关联行的行，这种联结称为外联结（outer join）。 内联结检索所有顾客及其订单： 123SELECT Customers.cust_id, Orders.order_numFROM Customers INNER JOIN OrdersON Customers.cust_id &#x3D; Orders.cust_id; 外联结语法类似，检索包括没有订单顾客在内的所有顾客： 123SELECT Customers.cust_id, Orders.order_numFROM Customers LEFT OUTER JOIN OrdersON Customers.cust_id &#x3D; Orders.cust_id; 使用OUTER JOIN语法时，必须使用RIGHT或LEFT关键字指定包括其所有行的表（RIGHT指出的是OUTER JOIN右边的表，而LEFT指出的是OUTER JOIN左边的表）。 上面的例子使用LEFT OUTER JOIN从FROM子句左边的表（Customers表）中选择所有行。为了从右边的表中选择所有行，需要使用RIGHT OUTER JOIN，如下例所示。 123SELECT Customers.cust_id, Orders.order_numFROM Customers RIGHT OUTER JOIN OrdersON Customers.cust_id &#x3D; Orders.cust_id; 还存在另一种外联结，就是全外联结（full outer join），它检索两个表中的所有行并关联那些可以关联的行，全外联结包含了两个表中的不关联的行。（Access、MariaDB、MySQL和SQLite不支持FULL OUTER JOIN语法） 123SELECT Customers.cust_id, Orders.order_numFROM Customers FULL OUTER JOIN OrdersON Customers.cust_id &#x3D; Orders.cust_id; 使用带聚集函数的联结使用COUNT()检索所有顾客及每个顾客所下的订单数： 12345SELECT Customers.cust_id, COUNT(Orders.order_num) AS num_ordFROM Customers INNER JOIN OrdersON Customers.cust_id &#x3D; Orders.cust_idGROUP BY Customers.cust_id; 聚集函数也可以方便地与其他联结一起使用。 12345SELECT Customers.cust_id, COUNT(Orders.order_num) AS num_ordFROM Customers LEFT OUTER JOIN OrdersON Customers.cust_id &#x3D; Orders.cust_idGROUP BY Customers.cust_id; 使用联结和联结条件联结及其使用的某些要点： 注意所使用的联结类型。一般我们使用内部联结，但使用外部联结也是有效的。 保证使用正确的联结条件，否则将返回不正确的数据。应该总是提供联结条件，否则会得出笛卡儿积。 在一个联结中可以包含多个表，甚至对于每个联结可以采用不同的联结类型。虽然这样做是合法的，一般也很有用，但应该在一起测试它们前，分别测试每个联结。这将使故障排除更为简单。 组合查询多数SQL查询都只包含从一个或多个表中返回数据的单条SELECT语句。MySQL也允许执行多个查询(多条SELECT语句)，并将结果作为单个查询结果集返回。这些组合查询通常称为并（ union)或复合查询(compound query)。 使用UNION12345SELECT vend_id, prod_id,prod_price FROM productsWHERE prod_price&#x3D; 5UNIONSELECT vend_id,prod_id,prod_price FROM productsWHERE vend_id IN (1001,1002); UNION规则 UNION必须由两条或两条以上的SELECT语句组成，语句之间用关键字UNION分隔。如果组合四条SELECT语句，将要使用三个UNION关键字。 UNION中的每个查询必须包含相同的列、表达式或聚集函数，各个列不需要以相同的次序列出。 列数据类型必须兼容：类型不必完全相同，但必须是DBMS可以隐含转换的类型（例如，不同的数值类型或不同的日期类型）。 UNION返回交集，这是默认行为，如果想返回所有匹配行，可使用UNION ALL UNION的组合查询可以应用不同的表 对组合查询结果排序在用UNION组合查询时，只能使用一条ORDER BY子句，它必须位于最后一条SELECT语句之后。 对于结果集，不存在用一种方式排序一部分，而又用另一种方式排序另一部分的情况，因此不允许使用多条ORDER BY子句。 12345678SELECT cust_name, cust_contact, cust_emailFROM CustomersWHERE cust_state IN (&#39;IL&#39;,&#39;IN&#39;,&#39;MI&#39;)UNIONSELECT cust_name, cust_contact, cust_emailFROM CustomersWHERE cust_name &#x3D; &#39;Fun4All&#39;ORDER BY cust_name, cust_contact; 全文本搜索理解全文本搜索MySQL支持几种基本的数据库引擎，两个最常使用的引擎为MyISAM和InnoDB。前者支持全本文搜索，后者不支持。 Like和正则的在搜索全文本的局限性： 性能 通配符和正则表达式匹配通常要求MySQL尝试匹配表中所有行（而且这些搜索极少使用表索引)。因此，由于被搜索行数不断增加，这些搜索可能非常耗时。 明确控制 使用通配符和正则表达式匹配，很难（而且并不总是能）明确地控制匹配什么和不匹配什么。例如，指定一个词必须匹配，一个词必须不匹配，而一个词仅在第一个词确实匹配的情况下才可以匹配或者才可以不匹配。 智能化的结果 虽然基于通配符和正则表达式的搜索提供了非常灵活的搜索,但它们都不能提供一种智能化的选择结果的方法。例如，一个特殊词的搜索将会返回包含该词的所有行，而不区分包含单个匹配的行和包含多个匹配的行(按照可能是更好的匹配来排列它们)。类似，一个特殊词的搜索将不会找出不包含该词但包含其他相关词的行。 全文本搜索方案：MySQL不需要分别查看每个行，不需要分别分析和处理每个词。MySQL创建指定列中各词的一个索引，搜索可以针对这些词进行。这样，MySQL可以快速有效地决定哪些词匹配（哪些行包含它们），哪些词不匹配，它们的匹配的频率，等等。 使用全文本搜索为了进行全文本搜索，必须索引被搜索的列，而且要随着数据的改变不断地重新索引。在对表列进行适当设计后，MySQL会自动进行所有的索引和重新索引。在索引之后,SELECT可与Match()和Against(）一起使用以实际执行搜索。 启用全文本搜索支持创建表时启用全文本搜索CREATE TABLE 语句 接受FULLTEXT子句 CREATE TABLE productnotes ( note_id int NOT NULL AUTO_INCREMENT, prod_id char(10) NOT NULL, note_date datetime NOT NULL, note_text text, PRIMARY KEY (note_id), FULLTEXT KEY note_text (note_text)) ENGINE=MyISAM; MySQL根据子句FULLTEXT(note_text)的指示对它进行索引，这里索引单个列，也可以索引多个列。 **不要在导入数据时使用FULLTEXT ** 更新索引要花时间,虽然不是很多,但毕竟要花时间。如果正在导入数据到一个新表,此时不应该启用FULLTEXT索引。应该首先导入所有数据,然后再修改表,定义FULLTEXT。这样有助于更快地导入数据(而且使索引数据的总时间小于在导入每行时分别进行索引所需的总时间). 通过 Alter Table 的方式来添加ALTER TABLE productnotes ADD FULLTEXT INDEX ft_prod_name(**note_text ) 或者： ALTER TABLE productnotes ADD FULLTEXT ft_prod_name(**note_text ) 直接通过create index的方式CREATE FULLTEXT INDEX ft_prod_name ON productnotes (note_text `) 指定索引的长度： CREATE FULLTEXT INDEX ft_prod_name ON productnotes (note_text `(20)) 进行全文本索索使用函数Match()和Against()Match()被搜索的列，Against()指定要使用的搜索表达式 SELECT NOTE_TEXT FROM productnotes WHERE MATCH(NOTE_TEXT) Against(‘rabbit’) 当查询结果很多，几乎所有记录都有，或者极少的数据，都有可能会返回非所期望的结果。 可用IN BOOLEAN MODE SELECT NOTE_TEXT FROM productnotes WHERE MATCH(NOTE_TEXT) Against(‘rabbit’ IN BOOLEAN MODE) 使用完整的Match()说明 传递给Match()的值必须与FULLTEXT()定义中的相同。如果指定多个列，则必须列出它们(而且次序正确)。 搜索不区分大小写 除非使用BINARY方式，否则全文本搜索不区分大小写。 搜索结果中，每行都有一个等级值 文本中词靠前的行的等级值比词靠后的行的等级值高。 排序多个搜索项 如果指定多个搜索项,则包含多数匹配词的那些行将具有比包含较少词(或仅有一个匹配)的那些行高的等级值。(降序) 使用查询拓展(anvils)在使用查询扩展时，MySQL对数据和索引进行两遍扫描来完成搜索: 首先，进行一个基本的全文本搜索，找出与搜索条件匹配的所有行; 其次，MySQL检查这些匹配行并选择所有有用的词 再其次，MySQL再次进行全文本搜索,这次不仅使用原来的条件，而且还使用所有有用的词。 SELECT note_text FROM productnotes WHERE Match(note_text) Against(‘anvils ‘); |note_text| |Multiple customer returns，anvils failing to drop fast enough or ll falling backwards on purchaser. Recommend that customer considers l[ using heavier anvi1s. 只有一行包含词anvils,因此只返回一行。 查询拓展:SELECT note_text FROM productnotes MHERE Match(note_text) Against(‘anvi1s’ WITH QUERY EXPANSION); 例子可参考网上，这里不贴出。 行越多越好表中的行越多 （这些行中的文本就越多),使用查询扩展返回的结果越好。 布尔文本搜索boolean mode(没有FULLTEXT索引也可以使用，但性能随着数据量的增加而降低) 要匹配的词; 要排斥的词（如果某行包含这个词，则不返回该行，即使它包含其他指定的词也是如此); 排列提示(指定某些词比其他词更重要，更重要的词等级更高);表达式分组;另外一些内容。 全文本布尔操作符 布尔操作符 说明 + 包含,词必须存在 - 排除,词必须不出现 &gt; 包含,而且增加等级值 &lt; 包含，且减少等级值 () 把词组成子表达式(允许这些子表达式作为一个组被包含、排除、排列等) ~ 取消一个词的排序值 * 词尾的通配符 “” 定义一个短语（与单个词的列表不一样，它匹配整个短语以便包含或排除这个短语) 排列而不排序 在布尔方式中，不按等级值降序排序返回的行。 全文本搜索的使用说明 在索引全文本数据时，短词被忽略且从索引中排除。短词定义为那些具有3个或3个以下字符的词(如果需要,这个数目可以更改)。 MySQL带有一个内建的非用词(stopword）列表，这些词在索引全文本数据时总是被忽略。如果需要，可以覆盖这个列表（请参阅MySQL文档以了解如何完成此工作)。 许多词出现的频率很高，搜索它们没有用处（返回太多的结果)。因此，MySQL规定了一条50%规则，如果一个词出现在50%以上的行中，则将它作为一个非用词忽略。50%规则不用于INBOOLEAN MODE。 如果表中的行数少于3行,则全文本搜索不返回结果(因为每个词或者不出现，或者至少出现在50%的行中)。 忽略词中的单引号。例如，don’t索引为dont。 不具有词分隔符（包括日语和汉语）的语言不能恰当地返回全文本搜索结果。如前所述,仅在My ISAM数据库引擎中支持全文本搜索。 目前MySQL不支持领近操作符 插入数据INSERT是用来插入（或添加）行到数据库表的。插入可以用几种方式使用: 插入完整的行; 插入行的一部分; 插入多行; 插入某些查询的结果。 MySQL允许针对每个表或每个用户使用安全机制禁止使用INSERT语句 插入完整的行INSERT指定表名和插入到新行中的值。 123INSERT INTO CustomersVALUES(&#39;1000000006&#39;,&#39;Pep E&#39;,&#39;123 Los Street&#39;, &#39;Main York&#39;,&#39;NY&#39;,&#39;11111&#39;,&#39;USA&#39;,NULL,NULL); 插入数据时，各列必须以它们在表定义中出现的次序填充。 上面的SQL语句高度依赖于表中列的定义次序，还依赖于其容易获得的次序信息。即使可以得到这种次序信息，也不能保证各列在下一次表结构变动后保持完全相同的次序。因此，编写依赖于特定列次序的SQL语句是很不安全的。 实际上，在插入数据的时候，最好给出填充列的顺序。 12345INSERT INTO Customers(cust_id,cust_contact,cust_email, cust_name,cust_address,cust_city, cust_state,cust_zip)VALUES(&#39;1000000006&#39;,NULL,NULL,&#39;Toy Land&#39;,&#39;123 Any Street&#39;, &#39;New York&#39;,&#39;NY&#39;,&#39;11111&#39;); 总是使用列的列表 一般不要使用没有明确给出列的列表的INSERT语句。使用列的列表能使SQL代码继续发挥作用,即使表结构发生了变化。 仔细地给出值 不管使用哪种INSERT语法,都必须给出VALUES的正确数目。如果不提供列名，则必须给每个表列提供一个值。如果提供列名,则必须对每个列出的列给出一个值。如果不这样,将产生一条错误消息,相应的行插入不成功。 省略列 如果表的定义允许,则可以在INSERT操作中省略某些列。省略的列必须满足以下某个条件。 该列定义为允许NULL值(无值或空值)。 在表定义中给出默认值。这表示如果不给出值，将使用默认值。 如果对表中不允许NULL值且没有默认值的列不给出值,则MySQL将产生一条错误消息，并且相应的行插入不成功。 提高整体性能 数据库经常被多个客户访问,对处理什么请求以及用什么次序处理进行管理是MySQL的任务。INSERT操作可能很耗时(特别是有很多索引需要更新时)，而且它可能降低等待处理的SELECT语句的性能。 如果数据检索是最重要的(通常是这样)，则你可以通过在INSERT和INTO之间添加关键字LOW_PRIORITY，指示MySQL降低INSERT语句的优先级,如下所示:INSERT LON_PRIORITY INTO里，这也适用UPDATE和DELETE语句。 多条INSERT语句 可以一次提交，每条使用一个分号结束。(单条语句比多条快) 插入检索出的数据(不推荐在生产环境使用)INSERT可以将SELECT语句的查询结果插入表中，这就是所谓的INSERT SELECT。它由一条INSERT语句和一条SELECT语句组成。 把另一个表中的顾客列合并到Customers表中: 123456INSERT INTO Customers(cust_id,cust_contact,cust_email, cust_name,cust_address,cust_city, cust_state,cust_zip,cust_country)SELECT cust_id,cust_contact,cust_email,cust_name,cust_address, cust_city,cust_state,cust_zip,cust_countryFROM CustNew; 更新和删除数据更新数据更新（修改）表中数据，可以使用两种UPDATE的方式： 更新表中的特定行。 更新表中的所有行。 基本的UPDATE语句由3部分组成： 要更新的表。 列名和它们的新值。 确定要更新哪些行的过滤条件。 不要省略WHERE子句 在使用UPDATE时一定要注意细心。因为稍不注意，就会更新表中所有行。 12UPDATE customersSET cust_emai1 &#x3D; &#39;e1mer@fudd.com&#39;WHERE cust_id &#x3D; 10005; 在UPDATE语句中使用子查询 UPDATE语句中可以使用子查询,使得能用SELECT语句检索出的数据更新列数据。 IGNORE关键字 如果用UPDATE语句更新多行,并且在更新这些行中的一行或多行时出一个现错误,则整个UPDATE操作被取消(错误发生前更新的所有行被恢复到它们原来的值)。为即使是发生错误，也继续进行更新,可使用IGNORE关键字， 如下所示: UPDATE IGNORE customers. 删除数据（删除表的内容而不是表本身）从一个表中删除（去掉）数据，可使用DELETE语句，两种使用DELETE的方式： 从表中删除特定的行。 从表中删除所有行。 基本的DELETE语句由两部分组成： 要删除的表。 确定要删除哪些行的过滤条件。 不要省略WHERE子句 在使用DELETE时一定要注意细心。因为稍不注意，就会错误地删除表中所有行。 可以限制和控制DELETE语句的使用，MySQL没有撤销(undo)按钮，所以你应该小心使用UPDATE和DELETE。 DELETE FROM customers WHERE cust_id - 10006; 更快的删除 如果想从表中删除所有行,不要使用DELETE.可使用TRUNCATE TABLE语句,它完成相同的工作,但速度更快(TRUNCATE实际是删除原来的表并重新创建一个表,而不是逐行删除表中的数据)。 下面是许多SQL程序员使用UPDATE或DELETE时所遵循的习惯。 除非确实打算更新和删除每一行，否则绝对不要使用不带WHERE子句的UPDATE或DELETE语句。 保证每个表都有主键(如果忘记这个内容，请参阅第15章)，尽可能像WHERE子句那样使用它(可以指定各主键、多个值或值的范围)。 在对UPDATE或DELETE语句使用WHERE子句前，应该先用SELECT进行测试，保证它过滤的是正确的记录，以防编写的WHERE子句不正确。 使用强制实施引用完整性的数据库，这样MySQL将不允许删除具有与其他表相关联的数据的行。（比如外键关联） 创建和操纵表创建表MySQL不仅用于表数据操纵，而且还可以用来执行数据库和表的所有操作，包括表本身的创建和处理。 一般有两种创建表的方法: 使用具有交互式创建和管理表的工具（如第2章讨论的工具); 表也可以直接用MySQL语句操纵。 123456789CREATE TABLE Products( prod_id char(10) NOT NULL , vend_id char(10) NOT NULL , prod_name char(255) NOT NULL , prod_price decimal(8,2) NOT NULL , prod_desc text NULL, PRIMARY KEY(prod_id))ENGINE&#x3D;InnoDB; 使用AUTO_INCREMENT(自增初始值可选)12345CREATE TABLE Products(cust_id int NOT NULL AUTO_INCREMENT,)AUTO_INCREMENT &#x3D; 100; 指定默认值添加默认值的时候，使用关键字DEFAULT。不允许函数 与大多数DBMS不一样,MySQL不允许使用函数作为默认值,它只支持常量。 使用默认值而不是NULL值 许多数据库开发人员使用默认值而不是NULL列,特别是对用于计算或数据分组的列更是如此。 更新表ALTER利用ALTER TABLE更新表，要考虑：理想情况下，不要在表中包含数据的时候对其进行更新，应该在创建表的时候，考虑未来的扩展性，避免对表的结构做大改动。 所有的DBMS都允许对现有表增加列，不过对所增加列的数据类型（以及NULL和DEFAULT的使用）有所限制。 多数DBMS允许重命名表中的列，不允许删除或更改表中的列。 复杂的表结构更改一般需要手动删除过程，它涉及以下步骤: 用新的列布局创建一个新表; 使用INSERT SELECT语句(关于这条语句的详细介绍，从旧表复制数据到新表。如果有必要，可使用转换函数和计算字段; 检验包含所需数据的新表; 重命名旧表（如果确定，可以删除它); 用旧表原来的名字重命名新表; 根据需要，重新创建触发器、存储过程、索引和外键。 删除表DROP TABLE customers2; 重命名表RENAME TABLE customers2 TO customers; 使用视图理解视图最好方法是看一个例子。用下面的SELECT语句从3个表中检索数据:1234SELECT cust_name,cust_contactFROM customers,orders, orderitemsWHERE customers.cust_id &#x3D; orders.cust_idAND orderitems.order_num &#x3D; orders.order_numAND prod_id &#x3D; &#39;TNT2 &#39;; 修改成不需要知道联结关系的视图12SELECT cust_name，cust_contact FROM productcustomersWHERE prod_id &#x3D; &#39;TNT2&#39;; 为什么要使用视图我们已经看到了视图应用的一个例子。下面是视图的一些常见应用。 重用SQL语句。 简化复杂的SQL操作。在编写查询后，可以方便地重用它而不必知道它的基本查询细节。 使用表的组成部分而不是整个表。 保护数据。可以给用户授予表的特定部分的访问权限而不是整个表的访问权限。 更改数据格式和表示。视图可返回与底层表的表示和格式不同的数据。 视图的规则和限制视图创建和使用的一些最常见的规则和限制。 与表一样，视图必须唯一命名（不能给视图取与别的视图或表相同的名字)。对于可以创建的视图数目没有限制。 为了创建视图，必须具有足够的访问权限。这些限制通常由数据库管理人员授予。 视图可以嵌套，即可以利用从其他视图中检索数据的查询来构造一个视图。 ORDER BY可以用在视图中，但如果从该视图检索数据SELECT中也含有ORDER BY，那么该视图中的ORDER BY将被覆盖。 视图不能索引，也不能有关联的触发器或默认值。 视图可以和表一起使用。例如，编写一条联结表和视图的SELECT语句。 创建视图视图是虚拟的表，只包含使用时动态检索数据的查询。 视图用CREATE VIEW语句来创建。 使用SHOW CREATE VIEW viewname;来查看创建视图的语句。 用DROP删除视图，其语法为DROP VIEW viewname;。 更新视图时，可先用DROP再用CREATE，也可以直接用CREATE OR REPLACE VIEW。如果要更新的视图不存在，则第2条更新语句会创建一个视图；如果要更新的视图存在，则第2条更新语句会替换原有视图。 **创建可重用的视图 **创建不受特定数据限制的视图是一种好办法。例如，上面创建的视图返回生产所有产品的客户 而不仅仅是生产TNT2的客户。扩展视图的范围不仅使得它能被重用,而且甚至更有用。这样做不需要创建和维护多个类似视图。 利用视图简化复杂的联结先创建ProductCustomers视图 12345CREATE VIEW ProductCustomers ASSELECT cust_name, cust_contact, prod_idFROM Customers, Orders, OrderItemsWHERE Customers.cust_id &#x3D; Orders.cust_idAND OrderItems.order_num &#x3D; Orders.order_num; 检索订购了产品RGAN01的顾客 123SELECT cust_name, cust_contactFROM ProductCustomersWHERE prod_id &#x3D; &#39;RGAN01&#39;; 用视图重新格式化检索出的数据将供应商Vendors表中的vend_name和vend_country合并输出显示 1234567CREATE VIEW VendorLocations ASSELECT concat(RTRIM(vend_name), &#39;(&#39;, RTRIM(vend_country), &#39;)&#39;)AS vend_titleFROM Vendors;SELECT * FROM VendorLocations; 用视图过滤不想要的数据定义CustomerEmailList视图，过滤没有Email的顾客。 1234567CREATE VIEW CustomerEmailList ASSELECT cust_id, cust_name, cust_emailFROM CustomersWHERE cust_email IS NOT NULL;SELECT * FROM CustomerEmailList; 使用视图与计算字段检索某个订单的产品，计算每种产品的总价格。 12345678CREATE VIEW OrderItemsExpanded ASSELECT order_num, prod_id, quantity, item_price, quantity * item_price AS expanded_priceFROM OrderItems;SELECT *FROM OrderItemsExpandedWHERE order_num &#x3D; 20008; 更新视图迄今为止的所有视图都是和SELECT语句使用的。然而，视图的数据能否更新？答案视情况而定。 通常，视图是可更新的，即，可以对它们使用INSERT、UPDATE和DELETE。更新一个视图将更新其基表，如果对视图增加或者删除行，实际上是对其基表增加或删除行。 但是，并非所有视图都是可更新的。基本上可以说，如果MySQL不能正确地确定被更新的基数据，则不允许更新（包括插入和删除）。 换句话说，如果视图定义中有以下操作，则不能进行视图的更新。 分组（使用GROUP BY和HAVING）。 联结。 子查询。 并。 聚集函数（MIN()、COUNT()等）。 DISTINCT。 导出（计算）列。 换句话说，本章的许多例子的视图都是不可更新的。这听上去好像是一个严重的限制，但实际上不是，因为视图主要用于数据检索。 一般，应该将视图用于检索（SELECT语句）而不用于更新（INSERT、UPDATE和DELETE）。 使用存储过程存储过程迄今为止，使用的大多数SQL语句都是针对一个或多个表的单条语句。并非所有操作都这么简单，经常会有一个完整的操作需要多条语句才能完成。 比如，考虑以下情况： 为了处理订单，需要核对以保证库存中有相应的物品。 如果库存有物品，这些物品需要预定以便不将它们再卖给别的人，并且要减少可用的物品数量以及反映正确的库存量。 库存中没有的物品需要订购，这需要与供应商进行某种交互。 关于哪些物品入库（并且可以立即发货）和哪些物品退订，需要通知相应的客户。 执行上述的例子，需要针对许多表的多条SQL语句。此外，需要执行的具体语句及其次序也不是固定的，它们可能会（和将）根据哪些物品在库存中，哪些不在而变化。 存储过程简单来说，就是为以后的使用而保存的一条或多条SQL语句的集合。可将其视为批文件，但它们的作用不限于批处理。 为什么要使用存储过程使用存储过程的主要理由： 通过把处理封装在容易使用的单元中，简化复杂的操作。 由于不要求反复建立一系列处理步骤，这保证了数据的完整性。如果所有开发人员和应用程序都使用同一（试验和测试）存储过程，则使用的代码都是相同的。（这一点的延伸就是防止错误，需要执行的步骤越多，出错的可能性就越大。防止错误保证了数据的一致性。） 简化对变动的管理。如果表名、列名或业务逻辑有变化，只需要更改存储过程的代码，使用它的人员甚至不需要知道这些变化。（这一点的延伸就是安全性，通过存储过程限制对基础数据的访问减少了数据讹误的机会。） 提高性能。因为使用存储过程比使用简单的SQL语句要快。 存在一些只能用在单个请求中的MySQL元素和特性，存储过程可以使用它们来编写功能更强更灵活的代码。 使用存储过程的3个主要好处就是：简单、安全、高性能。 存在的缺陷： 一般来说，存储过程的编写比基本SQL语句复杂，编写存储过程需要更高的技能，更丰富的经验。 可能没有创建存储过程的安全访问权限。许多数据库管理员限制存储过程的创建权限，允许用户使用存储过程，但不允许他们创建存储过程。 使用存储过程执行存储过程MySQL称存储过程的执行为调用，因此MySQL执行存储过程的语句为CALL。CALL接受存储过程的名字以及需要传递给它的任意参数。 1CALL productpricing(@pricelow,@pricehigh,@priceaverage); 执行名为productpricing的存储过程，它计算并返回产品的最低、最高和平均价格。 创建存储过程12345CREATE PROCEDURE productpricing()BEGIN SELECT AVG(prod_price) AS priceaverage FROM Products;END; 此存储过程名为分析productpricing, 用CREATE PROCEDURE productpricing()语句定义。如果存储过程接受参数，它们将在()中列举出来。此存储过程没有参数，但后跟的()仍然需要。BEGIN和END语句用来限定存储过程体，过程体本身仅是一个简单的SELECT语句。 由于默认的MySQL语句分隔符为;，如果命令行实用程序要解释存储过程自身内的;字符，则它们最终不会成为存储过程的成分，这会导致存储过程中的SQL出现句法错误 解决办法就是使用更改命令行实用程序的语法分隔符，如下所示： 123456789DELIMITER &#x2F;&#x2F; # 临时改成&#x2F;&#x2F;分隔符CREATE PROCEDURE productpricing()BEGIN SELECT AVG(prod_price) AS priceaverage FROM Products;END&#x2F;&#x2F;DELIMITER ; #恢复 分隔符 调用存储过程： 1CALL productpricing(); CALL productpricing();执行刚创建的存储过程并显示返回的结果。因为存储过程实际上是一种函数，所以存储过程名后需要有()符号，即使不传递参数也需要。 删除存储过程删除刚创建的存储过程： 1DROP PROCEDURE productpricing; #不需要()符号 使用带参数的存储过程productpricing只是一个简单的存储过程，它简单地显示SELECT语句的结果。一般，存储过程并不显示结果，而是把结果返回给你指定的变量。 注意：创建下面的存储过程的时候，记得先删除以前创建的productpricing。 1234567891011121314151617DELIMITER &#x2F;&#x2F;CREATE PROCEDURE productpricing( OUT pl DECIMAL(8,2), OUT ph DECIMAL(8,2), OUT pa DECIMAL(8,2))BEGIN SELECT MIN(prod_price) INTO pl FROM Products; SELECT MAX(prod_price) INTO ph FROM Products; SELECT AVG(prod_price) INTO pa FROM Products;END &#x2F;&#x2F;DELIMITER ; MySQL支持IN(传递给存储过程)、OUT(从存储过程传出) 参数的数据类型 存储过程的参数允许的数据类型与表中使用的数据类型相同。注意,记录集不是允许的类型,因此,不能通过一个参数返回多个行和列。这就是前面的例子为什么要使用3个参数(和3条SELECT语句)的原因。 为调用此存储过程，必须指定3个变量名： 123CALL productpricing(@pricelow, @pricehigh, @priceaverage); 变量名 所有MySQL变量都必须以@开始。 在调用时，这条语句并不显示任何数据。它返回以后可以显示（或在其他处理中使用）的变量。 12call productpricing(@max_id)select @max_id 创建另一个存储过程，这次使用IN和OUT参数。ordertotal接受订单号并返回该订单的合计： 1234567891011121314DELIMITER &#x2F;&#x2F;CREATE PROCEDURE ordertotal( IN onumber INT, OUT ototal DECIMAL(8,2))BEGIN SELECT SUM(item_price * quantity) FROM OrderItems WHERE order_num &#x3D; onumber INTO ototal;END &#x2F;&#x2F;DELIMITER ; 调用该存储过程时，必须给ordertotal传递两个参数：第一个参数为订单号，第二个参数为包含计算出来的合计的变量名。 12345CALL ordertotal(20005, @total);SELECT @total;CALL ordertotal(20009, @total);SELECT @total; 建立智能存储过程上述的所有存储过程基本上都是封装MySQL简单的SELECT语句，只有在存储过程内包含业务规则和智能处理时，它们的作用才能真正显现出来。 考虑如下场景，你需要获得与以前一样的订单合并，但需要对合计增加营业税，不过只针对某些顾客。那么，你需要做下面几件事情： 获得合计。 把营业税有条件地添加到合计。 返回合计（带税或者不带税）。 存储过程的完整工作如下（记得先删除以前创建的ordertotal存储过程）： 1234567891011121314151617181920212223242526DELIMITER &#x2F;&#x2F;CREATE PROCEDURE ordertotal( IN onumber INT, IN taxable BOOLEAN, OUT ototal DECIMAL(8,2))BEGIN # 声明局部变量 DECLARE total DECIMAL(8,2); DECLARE taxrate INT DEFAULT 6; SELECT SUM(item_price * quantity) FROM OrderItems WHERE order_num &#x3D; onumber INTO total; IF taxable THEN SELECT total + (total&#x2F;100 * taxrate) INTO total; END IF; # 结果保存到ototal中 SELECT total INTO ototal;END &#x2F;&#x2F;DELIMITER ; DECLARE语句定义了两个局部变量，DECLARE要求指定变量名和数据类型，它支持可选的默认值。IF语句检查taxable是否为真，如果为真，则用另一个SELECT语句增加营业税到局部变量total。最后，将局部变量total保存到ototal。 调用该存储过程： 12345CALL ordertotal(20005, 0, @total);SELECT @total;CALL ordertotal(20005, 1, @total);SELECT @total; 检查存储过程为显示用来创建一个存储过程的CREATE语句，使用SHOW CREATE PROCEDURE语句： 1SHOW CREATE PROCEDURE ordertotal; 为了获得包括何时、由谁创建等详细信息的存储过程列表，使用SHOW PROCEDURE STATUS。 1SHOW PROCEDURE STATUS; SHOW PROCEDURE STATUS;显示了太多无关紧要的信息，为限制其输出，可以使用LIKE指定一个过滤模式。例如： 1SHOW PROCEDURE STATUS LIKE &#39;ordertotal&#39;; 使用游标什么是游标(cursor)？MySQL检索操作返回一组称为结果集的行，这组返回的行都是与SQL语句相匹配的行（零行或多行），使用简单的SELECT语句没办法得到第一行、下一行或者前10行，也不存在每次一行地处理所有行的简单方法。有时，需要在检索出来的行中前进或后退一行或多行。这就是使用游标的原因。 只能用于存储过程 不像多数DBMS,MySQL游标只能用于存储过程(和函数)。 使用游标使用游标涉及几个明确的步骤。 在能够使用游标前，必须声明（定义）它。这个过程实际上没有检索数据，它只是定义要使用的SELECT语句。 对于填有数据的游标,根据需要取出（检索）各行。 在结束游标使用时，必须关闭游标。 创建游标使用DECLARE语句创建游标 12345CREATE PROCEDURE processorders (BEGIN DECLARE ordernumbers CURSORFOR SELECT order_num FROM orders; END; 打开和关闭游标游标用OPEN CURSOR来打开 OPEN ordernumbers 当游标处理完成后，应当使用如下语句关闭游标 CLOSE ordernumbers; CLOSE释放游标使用的所有内部内存和资源，因此在每个游标不再需要时都应该关闭。 声明过的游标不再需要再次声明，用OPEN语句打开它就可以。 隐含关闭 如果你不明确关闭游标，MySQL将会在到达END语句时自动关闭它。 12345678910CREATE PROCEDURE processorders(BEGIN -- Declare the cursor DECLARE ordernumbers CURSORFOR SELECT order_num FROM orders; -- 0pen the cursor OPEN ordernumbers; -- Close the cursor CLOSE ordernumbers;END; 使用游标数据使用FETCH语句分别访问它的每一行 FETCH指定搜索什么数据（所需的列），然后游标向前移动，不重复读取同一行 一个例子 123456789101112131415161718192021CREATE PROCEDURE processorders()BEGIN​ DECLARE o INT;​ DECLARE ordernumbers CURSOR​ FOR​ SELECT order_num FROM orders;​ ​ OPEN ordernumners;​ FETCH ordernumbers INTO o;​ CLOSE ordernumbers;END; 使用触发器执行某条MySQL语句时触发事件的处理 DELETE; INSERT; UPDATE 创建触发器在创建触发器时，需要给出4条信息:1234567唯一的触发器名;触发器关联的表;触发器应该响应的活动（DELETE、INSERT或UPDATE);触发器何时执行（处理之前或之后)。 创建触发器CREATE TRIGGER 123CREATE TRIGGR newproduct AFTER INSERT ON productsFOR EACH ROW SELECT &#39;Product added&#39; 删除触发器1DROP TRIGGER newproduct INSERT 触发器在INSERT触发器在INSERT语句执行之前或之后，需要知道以下几点： 在INSERT触发器代码内，可引用一个名为NEW的虚拟表，访问被插入的行; 在BEFORE INSERT触发器中，NEW中的值也可以被更新（允许更改被插入的值); 对于AUTO_INCREMENT列，NEW在INSERT执行之前包含0，在INSERT执行之后包含新的自动生成值。 例子 AUTO_INCREMENT列具有MySQL自动赋予的值 123CREATE TRIGGER neworder AFTER INSERT ON ordersFOR EACH ROW SELECT NEW.order_num DELETE触发器在DELETE触发器在DELETE语句执行之前或之后，需要知道以下几点： 在DELETE触发器代码内，你可以引用一个名为OLD的虚拟表,访问被删除的行; OLD中的值全都是只读的，不能更新 123456CREATE TRIGGER deleteorder BEFORE DELETE ON ordersFOR EACH ROWBEGIN INSERT INTO archive_orders(order_num,order_date,cust_id) VALUES(OLD.order_num,OLD.order_date,OLD.cust_id);END; UPDATE触发器在UPDATE触发器在UPDATE语句执行之前或之后，需要知道以下几点： 在UPDATE触发器代码中，你可以引用一个名为OLD的虚拟表访问以前（UPDATE语句前）的值，引用一个名为NEW的虚拟表访问更新后的值 在BEFORE UPDATE触发器中，NEW中的值可能也被更新（允许更改将要用于UPDATE语句中的值） OLD中的值全都是只读的，不能更新 12CREATE TRIGGER updatevendor BEFORE UPDATE ON vendorsFOR EACH ROW SET NEW.vend_state &#x3D; Upper(NEW.vend.state); 管理事务处理COMMIT 和 ROLLBACK事务处理可以用来维护数据库的完整性，它保证成批的MySQL操作要么完全执行，要么完全不执行。 关系数据库中A表和B表串行执行插入或更新操作，当A表执行操作完，B操作执行出错。可利用事务处理执行回退操作以恢复数据库到某个已知且安全的状态。 事务处理的几个术语： 事务(transaction）指一组SQL语句; 回退（rollback)指撤销指定SQL语句的过程; 提交（commit）指将未存储的SQL语句结果写入数据库表; 保留点(savepoint）指事务处理中设置的临时占位符(place-holder&gt;，你可以对它发布回退（与回退整个事务处理不同)。 控制事务处理MySQL使用下面的语句来标识事务的开始： 1START TRANSACTION 使用ROLLBACK（只能在一个事务处理内使用）123456SELECT * FROM ordertotals;START TRANSACTION;DELETE FROM ordertotals;SELECT * FROM ordertotals;ROLLBACK;SELECT * FROM ordertotals; 哪些语句可以回退? 事务处理用来管理INSERT、 UPDATE和DELETE语句。你不能回退SELECT语句。(这样做也没有什么意义。)你不能回退CREATE或DROP操作。事务处理块中可以使用这两条语句,但如果你执行回退,它们不会被撤销。 使用COMMIT一般MySQL语句都是直接针对数据库表执行和编写的，这就是隐含提交，即提交是自动进行的。但是在事务处理块中，提交不会自动进行，需要使用COMMIT语句进行提交 1234START TRANSACTIONDELETE FROM orderitems WHERE order_num &#x3D; 20010;DELETE FROM orders WHERE order_num &#x3D; 20010;COMMIT; 隐含事务关闭： 当COMMIT或ROLLBACK语句执行后，事务会自动关闭 使用保留点为了支持回退部分事务处理，必须能在事务处理块中合适的位置放置占位符。这样，如果需要回退，可以回退到某个占位符123SAVEPOINT delete1;ROLLBACK TO delete1; 保留点在事务处理完成（执行一条ROLLBACK或COMMIT）后自动释放，也可以使用RELEASE SAVEPOINT明确地释放保留点 更改默认的提交行为1SET autocommit&#x3D;0; autocommit标志决定是否自动提交更改，不管有没有COMMIT语句。设置autocommit为0指示MySQL不自动提交更改（直到autocommit被设置为真为止） 全球化和本地化字符集和校对顺序数据库表被用来存储和检索数据。不同的语言和字符集需要以不同的方式存储和检索。因此，MySQL需要适应不同的字符集(不同的字母和字符)，适应不同的排序和检索数据的方法。 在讨论多种语言和字符集时，将会遇到以下重要术语; 字符集为字母和符号的集合; 编码为某个字符集成员的内部表示; 校对为规定字符如何比较的指令。 使用字符集和校对顺序查看所支持的字符集完整列表 1SHOW CHARACTER SET 查看所支持校对的完整列表 1SHOW COLLATION 安全管理用户应该对他们需要的数据具有适当的访问权 访问控制多数用户只需要对表进行读和写，但少数用户甚至需要能创建和删除表; 某些用户需要读表，但可能不需要更新表; 你可能想允许用户添加数据，但不允许他们删除数据; 某些用户（管理员）可能需要处理用户账号的权限，但多数用户不需要; 你可能想让用户通过存储过程访问数据，但不允许他们直接访问数据;: 你可能想根据用户登录的地点限制对某些功能的访问。 管理用户MySQL用户账号和信息存储在名为mysql的MySQL数据库中。 123USE mysql;SELECT user FROM user 创建用户账号1CREATE USER BEN IDENTIFIDE BY &#39;p@$$w0rd&#39; 重新命名一个用户账号123##### RENAME USER ben TO bforta; 删除用户帐号123##### DROP USER bforta; 设置访问权限123##### SHOW GRANTS FOR bforata; 为设置权限，使用GRANT语句。GRANT要求你至少给出以下信息: 要授予的权限; 被授予访问权限的数据库或表; 用户名。 1GRANT SLECT ON crashcourse.* TO bforta #授予用户在crashcourse数据库所有表的select权限 GRANT的反操作，REVOKE撤销特定权限123##### REVOKE SELECT ON crashcourse.* FROM bforta; #如果权限不存在会报错 GRANT和REVOKE可在几个层次上控制访问权限: 整个服务器，使用GRANT ALL和REVOKE ALL; 整个数据库，使用ON database.*; 特定的表，使用ON database.table;口特定的列; 特定的存储过程。 权限 说明 ALL 除GRANT OPTION外的所有权限 ALTER 使用ALTER TABLE 使用ALTER TABLE 使用ALTER PROCEDURE和DROP PROCEDURE CREATE 使用CREATE TABLE CREATE ROUTINE 使用CREATE PROCEDURE CREATE TEMPORARY TABLES 使用CREATE TEMPORARY TABLE CREATE USER 使用CREATE USER、DROP USER、RENAME USER和REVOKE ALL PRIVILEGES CREATE VIEW 使用CREATE VIEW DELETE 使用DELETE DROP 使用DROP TABLE EXECUTE 使用CALL和存储过程 FILE 使用SELECT INTO OUTFILE和LOAD DATA INFILE GRANT OPTION 使用GRANT和REVOKE INDEX 使用CREATE INDEX和DROP INDEX INSERT 使用INSERT LOCK TABLES 使用LOCK TABLES PROCESS 使用SHOW FULL PROCESSLIST RELOAD 使用FLUSH REPLICATION CLIENT 服务器位置的访问 REPLICATION SLAVE 由复制从属使用 使用SELECT 使用SELECT SHOW DATABASES 使用SHOW DATABASES SHOW VIEW 使用SHOW CREATE VIEW SHUTDOWN 使用mysqladmin shutdown（用来关闭MySQL) SUPER 使用CHANGE MASTER、KILL、LOGS、PURGE、MASTER和SET GLOBAL。还允许mysqladmin调试登录 UPDATE 使用UPDATE USAGE 无访问权限 更改口令SET PASSWORD SET PASSWORD FOR bforta = Password(‘n3wp@$$s0rd’) 数据库维护备份使用命令行实用程序mysqldump转储所有数据库内容到某个外部文件。在进行常规备份前这个实用程序应该正常运行，以便能正确地备份转储文件。 可用命令行实用程序mysqlhotcopy从一个数据库复制所有数据(并非所有数据库引擎都支持这个实用程序)。 可以使用MySQL的BACKUP TABLE或SELECT INTO OUTFILE转储所有数据到某个外部文件。这两条语句都接受将要创建的系统文件名,此系统文件必须不存在，否则会出错。数据可以用RESTORETABLE来复原。 ANALYZE TABLE，用来检查表键是否正确。 诊断启动问题查看日志文件错误日志/data/hostname.err 查询日志/data/hostname.log 二进制日志/data/hostname-bin 缓慢查询日志/data/hostname-slow.log 改善性能首先，MySQL（与所有DBMS一样）具有特定的硬件建议。在学习和研究MySQL时，使用任何旧的计算机作为服务器都可以。但对用于生产的服务器来说，应该坚持遵循这些硬件建议。 一般来说，关键的生产DBMS应该运行在自己的专用服务器上。 MySQL是用一系列的默认设置预先配置的，从这些设置开始通常是很好的。但过一段时间后你可能需要调整内存分配、缓冲区大小等。(为查看当前设置,可使用SHOw VARIABLES;和 SHOWSTATUS;。) MySQL一个多用户多线程的DBMS，换言之，它经常同时执行多个任务。如果这些任务中的某一个执行缓慢，则所有请求都会执行缓慢。如果你遇到显著的性能不良,可使用SHOW PROCESSL IST显示所有活动进程(以及它们的线程ID和执行时间)。你还可以用KILL命令终结某个特定的进程(使用这个命令需要作为管理员登录)。 总是有不止一种方法编写同一条SELECT语句。应该试验联结、并、子查询等，找出最佳的方法。 使用EXPLAIN语句让MySQL解释它将如何执行一条SELECT语句。一般来说,存储过程执行得比一条一条地执行其中的各条MySQL语句快。 应该总是使用正确的数据类型。 决不要检索比需求还要多的数据。换言之，不要用SELECT *（除非你真正需要每个列)。有的操作（包括INSERT）支持一个可选的DELAYED关键字，如果使用它，将把控制立即返回给调用程序，并且一旦有可能就实际执行该操作。 在导入数据时，应该关闭自动提交。你可能还想删除索引(包括FULLTEXT索引)，然后在导入完成后再重建它们。 必须索引数据库表以改善数据检索的性能。确定索引什么不是一件微不足道的任务，需要分析使用的SELECT语句以找出重复的WHERE和ORDER BY子句。如果一个简单的WHERE子句返回结果所花的时间太长，则可以断定其中使用的列(或几个列）就是需要索引的对象。 你的SELECT语句中有一系列复杂的OR条件吗?通过使用多条SELECT语句和连接它们的UNION语句，你能看到极大的性能改进。 索引改善数据检索的性能,但损害数据插入、删除和更新的性能。如果你有一些表，它们收集数据且不经常被搜索，则在有必要之前不要索引它们。(索引可根据需要添加和删除。) LIKE很慢。一般来说，最好是使用FULLTEXT而不是LIKE。数据库是不断变化的实体。一组优化良好的表一会儿后可能就面目全非了。由于表的使用和内容的更改，理想的优化和配置也会改变。 最重要的规则就是，每条规则在某些条件下都会被打破。","categories":[{"name":"Mysql","slug":"Mysql","permalink":"http://www.postman.life/categories/Mysql/"}],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2020-11-17T14:39:02.458Z","updated":"2020-11-09T15:41:46.323Z","comments":true,"path":"2020/11/17/hello-world/","link":"","permalink":"http://www.postman.life/2020/11/17/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"http://www.postman.life/categories/ElasticSearch/"},{"name":"Linux","slug":"Linux","permalink":"http://www.postman.life/categories/Linux/"},{"name":"Bochs","slug":"Linux/Bochs","permalink":"http://www.postman.life/categories/Linux/Bochs/"},{"name":"Mysql","slug":"Mysql","permalink":"http://www.postman.life/categories/Mysql/"}],"tags":[]}